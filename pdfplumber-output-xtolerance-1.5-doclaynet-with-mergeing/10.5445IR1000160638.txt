Verhaltensentscheidung
fÃ¼r automatisierte Fahrzeuge
mittels Arbitrationsgraphen


Zur Erlangung des akademischen Grades eines
Doktors der Ingenieurwissenschaften (Dr.-Ing.)


von der KIT-FakultÃ¤t fÃ¼r Maschinenbau
des Karlsruher Instituts fÃ¼r Technologie (KIT)


angenommene


Dissertation


von


M.Sc. Piotr Franciszek Orzechowski


Tag der mÃ¼ndlichen PrÃ¼fung:
Hauptreferent:
Korreferent:


17.10.2022
Prof. Dr.-Ing. Christoph Stiller
Prof. Dr.-Ing. Tamim Asfour


Dieses Werk ist lizenziert unter einer Creative Commons
Namensnennung 4.0 International Lizenz (CC BY 4.0):
https://creativecommons.org/licenses/by/4.0/deed.de


Abstract


Automated driving promises to improve safety, comfort, and efficiency of road
traffic and has the potential to catalyze a fundamental transformation of mo-
bility. In addition to perceiving and interpreting its environment, an auto-
mated vehicle must reliably make safe and temporally consistent decisions â€”
for example, whether, when and how to change lanes.


Since specialized behavior planning solutions already exist for many scenar-
ios, the decision-making should be able to combine them appropriately. At
the same time, it must be robust against faulty outputs or even failures of
individual behavior options. Finally, the decision-making process should be
transparent and traceable to enable an effective development process.


Therefore, this work first proposes an application-independent system archi-
tecture for secure and robust behavioral decision-making. It assembles basic
behavior blocks in a hierarchical arbitration graph and ensures safety through
verification and diverse levels of fallback. The respective behavior blocks are
responsible for situation interpretation and behavior planning, while generic
arbitrators carry out the decision process.


This architecture is then applied to the context of automated driving and eval-
uated in simulation. Thereby, the behavior options plan individual driving
maneuvers and output them as trajectories. Multiple verifiers check these
for feasibility, drivability and road safety. If a driving maneuver turns out to
be unsafe, for example, the arbitration uses its alternative options and three
fallback levels to continue generating safe behavior.


The evaluation shows that the presented method produces safe and stable
driving behavior even at high failure rates. Meanwhile, the decoupling of sit-
uation interpretation and decision-making contributes to a transparent and


comprehensible decision-making process. This rigorous modularity allows to
combine a wide range of behavior planning methods in an efficient and scal-
able manner. In addition, the bottom-up design leads to fast prototyping and
iterative enhancement of the overall system.


Kurzfassung


Automatisiertes Fahren verspricht die Sicherheit, den Komfort und die Effi-
zienz des StraÃŸenverkehrs zu verbessern und hat das Potenzial eine grund-
legende Transformation der MobilitÃ¤t anzustoÃŸen. Neben der Wahrnehmung
und Interpretation seines Umfelds muss ein automatisiertes Fahrzeug zuver-
lÃ¤ssig sichere und zeitlich konsistente Entscheidungen treffen â€” bspw. ob,
wann und wie ein Fahrstreifenwechsel durchgefÃ¼hrt wird.


Da es fÃ¼r viele Szenarien bereits spezialisierte LÃ¶sungsansÃ¤tze zur Verhaltens-
planung gibt, sollte die Verhaltensentscheidung in der Lage sein, diese sinn-
voll miteinander zu kombinieren. Gleichzeitig muss sie robust gegen fehler-
hafte Ausgaben oder gar AusfÃ¤lle einzelner Verhaltensoptionen sein. SchlieÃŸ-
lich sollte der Entscheidungsprozess transparent und nachvollziehbar sein,
um einen effektiven Entwicklungsprozess zu ermÃ¶glichen.


Daher wird in dieser Arbeit zunÃ¤chst eine anwendungsunabhÃ¤ngige System-
architektur zur sicheren und robusten Verhaltensentscheidung vorgeschla-
gen. Diese setzt grundlegende Verhaltensoptionen in einem hierarchischen
Arbitrationsgraphen zusammen und sichert dabei die StellgrÃ¶ÃŸen mittels
Verifikation und diversen RÃ¼ckfallebenen ab. Die jeweiligen Verhaltensbau-
steine Ã¼bernehmen dabei die Situationsinterpretation und Verhaltensplanung,
wÃ¤hrend generische Arbitratoren den Entscheidungsprozess realisieren.


AnschlieÃŸend wird diese Architektur auf den Kontext des automatisierten
Fahrens angewandt und in Simulation evaluiert. Dabei planen die Verhaltens-
optionen einzelne FahrmanÃ¶ver und geben diese als Trajektorien aus. Drei Ve-
rifikatoren prÃ¼fen diese auf GÃ¼ltigkeit, Realisierbarkeit und Verkehrssicher-
heit. Stellt sich ein FahrmanÃ¶ver bspw. als unsicher heraus, greift die Arbi-
tration auf Alternativoptionen und drei RÃ¼ckfallebenen zurÃ¼ck, um weiterhin
ein sicheres Verhalten zu erzeugen.


Die Evaluation zeigt, dass die vorgestellte Methode auch bei hohen Ausfall-
raten ein sicheres und stabiles Fahrverhalten erzeugt. Die Entkopplung von
Situationsinterpretation und Verhaltensentscheidung trÃ¤gt auÃŸerdem zu einer
transparenten und nachvollziehbaren Entscheidungsfindung bei. Dank kon-
sequenter ModularitÃ¤t kÃ¶nnen vielfÃ¤ltige Methoden der Verhaltensplanung
effizient und skalierbar miteinander kombiniert werden. Zudem ermÃ¶glicht
der Bottom-Up Entwurf schnelles Prototyping und eine iterative Weiterent-
wicklung des Gesamtsystems.


Danksagung


Die vorliegende Arbeit entstand wÃ¤hrend meiner TÃ¤tigkeit als wissenschaftli-
cher Mitarbeiter am Institut fÃ¼r Mess- und Regelungstechnik (MRT) des Karls-
ruher Instituts fÃ¼r Technologie (KIT) sowie am FZI Forschungszentrum In-
formatik. Sie wÃ¤re nicht mÃ¶glich gewesen ohne die vielfÃ¤ltige UnterstÃ¼tzung
meiner KollegInnen, Familie und Freunde.


ZunÃ¤chst mÃ¶chte ich mich bei Herrn Prof. Dr.-Ing. Christoph Stiller bedanken,
fÃ¼r die MÃ¶glichkeit der Promotion und die tollen Rahmenbedingungen, die er
am MRT geschaffen hat. Besonders habe ich zu schÃ¤tzen gelernt, dass Ergeb-
nisse direkt auf den VersuchstrÃ¤gern integriert und anschlieÃŸend auf Demos
sowie im Ã¶ffentlichen StraÃŸenverkehr in Aktion gebracht werden konnten.
Ebenso danke ich Prof. Dr.-Ing. Tamim Asfour fÃ¼r die Ãœbernahme des Korre-
ferats und das inhaltliche Feedback aus Sicht der humanoiden Robotik. FÃ¼r die
inhaltliche Inspiration zu den Arbitratoren und hervorragende wissenschaft-
liche Betreuung mÃ¶chte ich Herrn Dr. rer. nat. Martin Lauer danken.


Meine Promotion startete ich insbesondere aus der Motivation heraus, ein
wissenschaftliches Thema anwendungsnah zu erforschen und im Team um-
zusetzen. Am MRT habe ich hierfÃ¼r ein tolles Doktorandenkollegium gefun-
den, geprÃ¤gt von Teamgeist, Ansporn und SpaÃŸ an der Sache. Ich verzich-
te darauf, alle KollegInnen aufzuzÃ¤hlen, hat doch jeder seinen Teil beigetra-
gen. Daher bedanke ich mich bei allen fÃ¼r die anregenden sowie unterhaltsa-
men Fach- und Triviadiskussionen in unseren Sommerseminaren, Gruppen-
meetings, Konferenzbesuchen, Social-Tuesdays und endlosen Kaffeepausen.
Ganz konkret einen Dank fÃ¼r das Korrekturlesen an Frank, Hendrik, Jan, Ling-
guang, Martin, Nick und Sahin. SchlieÃŸlich ein besonderer Dank an Christoph
fÃ¼r die enge inhaltliche Zusammenarbeit an den Arbitrationsgraphen. Chris-
toph hat einen wesentlichen Beitrag zum Gelingen dieser Arbeit beigetragen.


Auch dem Sekretariat mÃ¶chte ich danken, das durch seinen Einsatz einen rei-
bungslosen Forschungs- und Lehrbetrieb ermÃ¶glicht. Ebenso den Kollegen
aus den WerkstÃ¤tten mein Dank, sie erwecken groÃŸe sowie kleine Versuchs-
trÃ¤ger zum Leben und halten sie fÃ¼r die Doktoranden und Studis am Laufen.


Einen GruÃŸ mÃ¶chte ich auch an die Hochschulgruppe KITcar aussprechen, die
mich in meinem Masterstudium sehr geprÃ¤gt und letztlich zu der Promotion
im Automatisierten Fahren gebracht hat.


Nicht zuletzt mÃ¶chte ich meinen Eltern von Herzen danken. Sie haben mich
von klein auf geliebt, gefÃ¶rdert und ermutigt â€“ und somit im weiteren Sinne
die Grundlage fÃ¼r diese Arbeit geschaffen. Mein grÃ¶ÃŸter Dank gilt meiner Frau
Anjuli, die mich tagtÃ¤glich bereichert, inspiriert, stÃ¤rkt und unterstÃ¼tzt. Ohne
ihren RÃ¼ckhalt hÃ¤tte ich diese Arbeit vermutlich nicht zu Ende gebracht.


1 Einleitung


Dieses Kapitel stellt zunÃ¤chst die Motivation fÃ¼r die vorliegende Dissertati-
on, sowie das zugrunde liegende Arbeitsumfeld vor. AnschlieÃŸend wird in
Abschnitt 1.2 der Stand der Technik zu verwandten Forschungsthemen um-
rissen, bevor Abschnitt 1.3 die BeitrÃ¤ge dieser Arbeit zusammenfasst und Ab-
schnitt 1.4 einen Ãœberblick Ã¼ber die weiteren Kapitel gibt.


1.1 Motivation und Umfeld der Arbeit


Fahrerassistenzsysteme und automatisiertes Fahren haben in den letzten vier
Jahrzehnten enorme Fortschritte erreicht [Ben14, Bad21]. Trotz gestiegener
Neuzulassungen hat die Fahrerassistenz auf Stabilisierungsebene, wie ABS
und ESP, die Zahl tÃ¶dlicher UnfÃ¤lle drastisch reduzieren kÃ¶nnen. Dies leite-
te u. a. die Entwicklung von Unfallwarn- und Komfortsystemen ein, die sich
mittlerweile fest auf dem Automobilmarkt etabliert haben. Das automatisierte
Fahren stellt den nÃ¤chsten Schritt dar, bei dem das Fahrzeug je nach Automa-
tisierungsgrad die dynamische Fahraufgabe teilweise oder sogar ganz vom
Menschen Ã¼bernimmt [SAE21].


Durch diese weitere Automatisierung soll die Verkehrssicherheit sowie der
Fahrkomfort noch weiter erhÃ¶ht sowie der Verkehrsfluss optimiert und somit
Emissionen reduziert werden. ZusÃ¤tzlich werden vollautomatisierte Fahrzeu-
ge neue Formen der MobilitÃ¤t ermÃ¶glichen, die sogar gesellschaftliche The-
men wie die soziale Teilhabe mobilitÃ¤tseingeschrÃ¤nkter Menschen berÃ¼hren.
ErhÃ¶ht sich durch die Automatisierung zudem die AttraktivitÃ¤t von Carsha-
ring und anderen alternativen MobilitÃ¤tsformen, besteht die Chance heuti-
ge ParkflÃ¤chen wieder zu lebenswerten Ã¶ffentlichen RÃ¤umen umzugestalten.


SchlieÃŸlich werden die hohen Investitionen zweifellos auch durch wirtschaft-
liche Ãœberlegungen, wie bspw. Kosteneinsparungen in der Logistik und der
PersonenbefÃ¶rderung, motiviert. Einerseits sind in diesen Branchen folglich
Arbeitsplatzverluste zu erwarten [Moh22], andererseits verschlechtern sich
die Arbeitsbedingungen von Berufskraftfahrern in der Logistik immer wei-
ter [Dri14, GÃ¶t22]. VerkehrsverbÃ¼nde im Ã–ffentlichen Personennahverkehr
haben zudem seit Jahren Schwierigkeiten ausreichend Berufskraftfahrer zu
finden [VÃ¶l18].


Teil- oder vollautomatisiertes Fahren hat also das Potenzial, die Art und Weise
wie wir uns fortbewegen grundlegend hin zu einer sicheren, effizienten, nach-
haltigen und inklusiven MobilitÃ¤t zu verÃ¤ndern. Begleitet wird diese Trans-
formation von einem Wandel in der Arbeitswelt des MobilitÃ¤tssektors und
weiteren, bisweilen kaum voraussehbaren, SekundÃ¤reffekten.


Angetrieben durch die positiven GestaltungsmÃ¶glichkeiten sowie technologi-
sche SprÃ¼nge im Bereich des Maschinellen Lernens, haben die Forschungsan-
strengungen im Bereich der Fahrerassistenzsysteme und vollautomatisierter
Fahrzeuge zuletzt sowohl im akademischen als auch im kommerziellen Be-
reich drastisch zugenommen. Dabei muss ein automatisiertes Fahrzeug sei-
ne Umgebung zum einen zuverlÃ¤ssig wahrnehmen, zum anderen auf dieser
Grundlage sichere FahrmanÃ¶ver generieren. Die Verhaltensentscheidung be-
stimmt hierfÃ¼r Zeitpunkt, Art und AusprÃ¤gung des geplanten FahrmanÃ¶vers
â€“ also ob, wie, wo und wann bspw. ein Fahrstreifenwechsel stattfinden oder
wann und in welche ParklÃ¼cke eingeparkt werden soll. Gleichzeitig stellt sie
sicher, dass das Verhalten zeitlich konsistent, komfortabel, zielfÃ¼hrend und
sicher ist.


WÃ¤hrend die Wahrnehmung auf groÃŸen DatensÃ¤tzen evaluiert werden kann,
wird die Regelung in Simulation, mittels Hardware-in-the-Loop oder auf ge-
schlossenem TestgelÃ¤nde auf dem Fahrzeug erprobt. Zwar kÃ¶nnen auch Teile
der Verhaltensgenerierung in Simulation validiert werden, allerdings hÃ¤ngt
ihre LeistungsfÃ¤higkeit stark von der Interaktion mit anderen Verkehrsteil-
nehmern im realen StraÃŸenverkehr ab, da menschliches Verhalten in Simu-
lation nur unzureichend modelliert werden kann. Daher ist eine sichere und


robuste Verhaltensentscheidung von wesentlicher Bedeutung, um die Erpro-
bung und den spÃ¤teren Einsatz von automatisierten Fahrzeugen im StraÃŸen-
verkehr zu ermÃ¶glichen.


Gleichzeitig besteht der Bedarf fÃ¼r eine skalierende und generalisierende Soft-
warearchitektur, die es ermÃ¶glicht, die vielfÃ¤ltigen erprobten Verfahren zur
Verhaltensplanung in bestimmten Szenarien [Hoe17, Mir18, Hub19, Deb21]
â€“ einschlieÃŸlich klassischer und probabilistischer Methoden sowie AnsÃ¤tzen
des Maschinellen Lernens â€“ in einer Ã¼bergeordneten Verhaltensentscheidung
miteinander zu kombinieren. Unternehmen wie Waymo und Uber setzen die
Generierung von taktischem und strategischem Verhalten jedoch ausschlieÃŸ-
lich mittels Maschinellem Lernen, in Teilen sogar in sog. Ende-zu-Ende Archi-
tekturen, um [Ban19, Cas21]. Deutsche Fahrzeughersteller und -zulieferer set-
zen hingegen auf klassische AnsÃ¤tze, wie Endliche Zustandsautomaten oder
EntscheidungsbÃ¤ume [Aeb15], die eine solche Kombination von Methoden er-
mÃ¶glicht. Aber auch kleinere Forschungseinrichtungen, bspw. aus dem uni-
versitÃ¤ren Kontext, setzen auf regelbasierte Verfahren zur Entscheidungsfin-
dung, weil diese einfach umzusetzen und schnell einsatzbereit sind. Bei stei-
gender Anzahl an Verhaltensoptionen leiden solche AnsÃ¤tze in der Regel je-
doch unter schlechter ErklÃ¤rbarkeit, Wartbarkeit und Skalierbarkeit. Daher
hat die Robotik viele Architekturen hervorgebracht, um diese Probleme zu
adressieren. Darunter sind die verhaltensbasierten Systeme und ihre Derivate
besonders interessant.


Vor diesem Hintergrund wird in der vorliegenden Arbeit ein vielversprechen-
des, verhaltensbasiertes Verfahren zur Entscheidungsfindung aus der Robotik
aufgegriffen und auf den Anwendungsbereich des automatisierten Fahrens
Ã¼bertragen. AnschlieÃŸend wird die Methode mit MaÃŸnahmen aus der For-
schung zu zuverlÃ¤ssigen und fehlertoleranten Systemen sowie der Verkehrs-
sicherheit erweitert, um schlieÃŸlich eine sichere und robuste Verhaltensent-
scheidung fÃ¼r automatisierte Fahrzeuge zu realisieren. Die vorgeschlagene
Methode nutzt modulare Verhaltensbausteine in einem hierarchischen Ar-
bitrationsgraphen, ist skalierbar in der Anzahl der Verhaltensoptionen und
ermÃ¶glicht die Kombination vielfÃ¤ltiger szenariospezifischer Verfahren. Au-
ÃŸerdem gewÃ¤hrleistet sie eine robuste AusfÃ¼hrung und sicheres Verhalten


durch Verifikation und diverse RÃ¼ckfallebenen. Der modulare und hierarchi-
sche Aufbau ermÃ¶glicht zudem einen iterativen Entwurfsprozess, erhÃ¶ht die
Wartbarkeit und fÃ¼hrt zu einer transparenten sowie nachvollziehbaren Ent-
scheidungsfindung.


1.2 Stand der Technik


Die Literatur ist reich an diversen Verfahren zur Verhaltens- bzw. Trajektori-
enplanung in spezifischen Situationen sowie zur Verhaltensentscheidung, die
einer Strategie folgend zwischen diesen ManÃ¶veroptionen wÃ¤hlt. Dabei tref-
fen erstere teilweise auch implizite kombinatorische ManÃ¶verentscheidun-
gen, bspw. wann und in welche LÃ¼cke sich das Fahrzeug in einem Kreisver-
kehr einordnet [Deb21]. Mittels Verhaltensverifikation soll zudem gewÃ¤hr-
leistet werden, dass nur sichere FahrmanÃ¶ver ausgefÃ¼hrt werden. Im Folgen-
den wird der Stand der Technik in diesen drei Forschungsfeldern beleuchtet.


1.2.1 Verhaltensplanung


Zu den klassischen Methoden der Trajektorienoptimierung zÃ¤hlen u. a.
Graphensuchverfahren aus der Dynamischen Programmierung, die Mo-
dellprÃ¤diktive Regelung zur LÃ¶sung des Optimalsteuerungsproblems und
direkte oder indirekte Methoden aus der statischen Optimierung [Wer17].
2013 wurde die sog. Bertha Benz Memorial Route nahezu vollstÃ¤ndig auto-
matisiert befahren. Die Trajektorienplanung wurde hierbei als quadratisches
Optimierungsproblem formuliert und mittels Sequentieller Quadratischer
Programmierung gelÃ¶st [Zie14a]. Gutjahr u. a. [Gut17] schlagen hingegen
eine lineare ModellprÃ¤diktive Regelung vor, um ein linear-quadratisches
Optimalsteuerungsproblem zu lÃ¶sen. Durch eine geschickte Modellierung
konvergiert das Verfahren garantiert und auÃŸergewÃ¶hnlich schnell, sofern
eine LÃ¶sung existiert. SchlieÃŸlich bestimmen Banzhaf u. a. [Ban18] Trajek-
torien zum ManÃ¶vrieren in engen Umgebungen mittels Rapidly-exploring


Random Trees (RRT*) und kinematischen Bewegungsmodellen. Bemerkens-
wert ist, dass hierbei auch zu erwartende Unsicherheiten in der Regelung
und Lokalisierung berÃ¼cksichtigt werden.


Neben AnsÃ¤tzen aus der Regelungstechnik und Optimierungstheorie ge-
winnen probabilistische Methoden sowie Verfahren des Maschinellen Ler-
nens immer mehr Aufmerksamkeit [Kir21]. Partiell beobachtbare Markow-
Entscheidungsprobleme (POMDPs) werden eingesetzt, um Unsicherheiten
explizit in das Entscheidungsproblem zu integrieren. Somit werden Aktionen
gefÃ¶rdert, die dazu beitragen Unsicherheiten bspw. in der Wahrnehmung
und PrÃ¤diktion zu reduzieren. Hubmann u. a. [Hub18a] planen Trajektorien
fÃ¼r komplexe Kreuzungssituationen entlang eines vorab bestimmten Pfades,
wobei die nur indirekt beobachtbare Routenintention anderer Verkehrsteil-
nehmer mittels POMDP optimal in die Planung einbezogen wird.


AnsÃ¤tze des Maschinellen Lernens, auch die des BestÃ¤rkenden Lernens, bauen
hÃ¤ufig auf erfolgreiche KÃ¼nstliche Neuronale Netze aus der Bildverarbeitung
auf. Beispielsweise projizieren Chen u. a. [Che19] die Eingangsdaten in Vogel-
perspektive, reduzieren dieses generierte Bild mithilfe eines Autoencoders in
eine niedrig-dimensionale ReprÃ¤sentation (sog. Latente Zustandscodierung)
und speisen diese bspw. in eine Actor-Critic-Architektur ein. Hiermit gelingt
es der Methode die Quer- und LÃ¤ngsplanung fÃ¼r einen komplexen, stark be-
fahrenen Kreisverkehr zu realisieren.


1.2.2 Verhaltensentscheidung


Im Bereich der Verhaltensentscheidung finden sich sowohl monothematische
Methoden als auch generische Architekturen, die es ermÃ¶glichen diverse Ver-
fahren der Verhaltensplanung zu kombinieren. Insbesondere Ende-zu-Ende
Architekturen des Maschinellen Lernens, setzen auf einen einheitlichen An-
satz fÃ¼r alle mÃ¶glichen ManÃ¶ver- und Trajektorienvarianten. In [Cas21] wird
die gesamte Verarbeitungskette â€“ von der Wahrnehmung, Ã¼ber die Onlinekar-
tierung bis hin zur Routenplanung â€“ gelernt. Die Trajektorienkandidaten wer-
den aus einer Datenbank real beobachteter Experten-Trajektorien entnom-
men und mit einer ebenfalls gelernten Kostenfunktion bewertet.


Solche AnsÃ¤tze des Maschinellen Lernens haben, neben einer einheitlichen
Formulierung, den Vorteil, dass sie Unsicherheiten in der Situationsinterpre-
tation implizit mit berÃ¼cksichtigen. Allerdings sind hierzu meist enorme Da-
tenmengen und eine leistungsfÃ¤hige Rechnerinfrastruktur notwendig. Zudem
bieten sie beim Entwurf und der Weiterentwicklung nur sehr indirekte MÃ¶g-
lichkeiten das Systemverhalten zu beeinflussen. Wird also in spezifischen Si-
tuationen ein Fehlverhalten beobachtet, ist es schwierig dies gezielt zu ver-
bessern, zumal bei SystemÃ¤nderungen im Zweifelsfall auch das Verhalten in
anderen Situationen verÃ¤ndert wird.


Klassische Architekturen der Verhaltensentscheidung kÃ¶nnen solche Kopp-
lungen reduzieren oder gar vollstÃ¤ndig aufheben. AuÃŸerdem erlauben sie den
Einsatz unterschiedlicher Verfahren zur Verhaltensplanung, sodass je nach
angestrebter FunktionalitÃ¤t oder adressierter Situation die hierfÃ¼r bestmÃ¶g-
liche Methode eingesetzt werden kann. ZunÃ¤chst wurden vielfach zustands-
basierte Architekturen, wie Endliche Zustandsautomaten verwendet, um je
nach Situation einen geeigneten Fahrmodus zu wÃ¤hlen [Mon08, Zie14b]. In
[Mon08] bspw. bilden die ZustÃ¤nde verschiedene ManÃ¶veroptionen â€“ z. B.
Freie Fahrt, Kreuzung passieren, Einparken und Wenden â€“ ab. [Ard11] stellt
ein hybrides Konzept vor, das Endliche Zustandsautomaten und Entschei-
dungsbÃ¤ume fÃ¼r das hochautomatisierte Fahren auf Autobahnen kombiniert.
Ein Ã¼bergeordnetes Netzwerk aus hybriden deterministischen Zustandsauto-
maten bestimmt dabei den Systemzustand. Daraufhin bestimmen zwei Ent-
scheidungsbÃ¤ume den Fahrwunsch, prÃ¼fen die DurchfÃ¼hrbarkeit von ManÃ¶-
veroptionen und legen schlieÃŸlich jeweils den Modus fÃ¼r die Quer- und LÃ¤ngs-
fÃ¼hrung fest.


Zustandsbasierte Architekturen sind i. d. R. einfach umzusetzen und kÃ¶nnen
verschiedene Verfahren zur Verhaltensplanung miteinander kombinieren.
Durch ihren Top-Down Ansatz muss allerdings im Entwurfsprozess, wie auch
der Weiterentwicklung, stets das Gesamtsystem und die Wechselwirkungen
einzelner ZustÃ¤nde miteinander berÃ¼cksichtigt werden. Bei einer groÃŸen
Zahl an ZustÃ¤nden wird somit die KomplexitÃ¤t von bspw. Endlichen Zu-
standsautomaten nicht mehr beherrschbar. Folglich skalieren solche Systeme
nur schlecht mit der Anzahl an Verhaltensoptionen.


Als Gegenentwurf zu zustandsbasierten Architekturen haben sich in der
Robotik, ausgehend von Brooksâ€™ Subsumptionskonzept [Bro86], zahlreiche
verhaltensbasierte Methoden entwickelt. Diese setzen das Gesamtverhalten
im Bottom-Up Design aus einfachen Teilverhalten zusammen. Die Com-
puterspielbranche brachte hieraus spÃ¤ter die VerhaltensbÃ¤ume hervor, die
zunÃ¤chst in [Ã–gr12] konzeptionell fÃ¼r unbemannte Luftfahrzeuge eingesetzt
und anschlieÃŸend auf weitere Anwendungsgebiete der Robotik Ã¼bertragen
wurden [Col18]. Dabei wird die Verhaltensentscheidung Ã¼ber eine Baum-
struktur mittels sog. Kontrollfluss-Knoten realisiert. Die BlÃ¤tter des Baumes
Ã¼bernehmen hingegen die Verhaltensplanung oder gar Regelung, wobei sie
direkten Zugriff auf Sensorik und Aktorik haben kÃ¶nnen.


UnabhÃ¤ngig davon wurden im RoboterfuÃŸball Arbitrationsgraphen entwor-
fen, die u. a. das Subsumptionskonzept mit Objektorientierter Programmie-
rung kombinieren [Lau10]. Dabei adressieren modulare Verhaltensbausteine
grundlegende Verhaltenskompetenzen und Ã¼bernehmen auÃŸerdem die zuge-
hÃ¶rige Situationsinterpretation. Jeder Verhaltensbaustein gibt also selbststÃ¤n-
dig an, ob sein Verhalten in der vorliegenden Situation sinnvoll anwendbar
ist. Auf dieser Grundlage entscheiden anwendungsunabhÃ¤ngige Arbitrato-
ren, die in einer hierarchischen Graphstruktur angeordnet sind, welche Ver-
haltensoption voraussichtlich am geeignetsten ist. Einheitliche Eingabe- und
Ausgabeschnittstellen der Verhaltensbausteine und Arbitratoren stellen ih-
re Wiederverwendbarkeit sicher und erhÃ¶hen zugleich die VerstÃ¤ndlichkeit
des Gesamtsystems. In [Orz20] wurden Arbitrationsgraphen erstmalig in den
Kontext des automatisierten Fahrens Ã¼bertragen und ihre VorzÃ¼ge in Simula-
tion validiert. Die Verhaltensbausteine realisieren dabei einzelne FahrmanÃ¶-
ver, wie Folgefahrt, Fahrstreifenwechsel und Einparken. FÃ¼r die Verhaltens-
entscheidung wurden Arbitratoren eingesetzt, die zwischen diesen Optionen
nach festgelegter PrioritÃ¤t und zu erwartenden Routingkosten wÃ¤hlen.


Verhaltensbasierte Architekturen zeichnen sich u. a. durch eine hohe Reak-
tivitÃ¤t, konsequente ModularitÃ¤t und entsprechend gute Skalierbarkeit aus.
Sie sind vergleichbar einfach umzusetzen wie zustandsbasierte Architektu-
ren, und kÃ¶nnen ebenfalls verschiedene Verfahren der Verhaltensplanung in


einem Gesamtsystem kombinieren. ZusÃ¤tzlich bieten sie durch ihren hierar-
chisch modularen Aufbau eine optimale Struktur, um einen Verifikationsme-
chanismus mit RÃ¼ckfallebenen direkt in die Verhaltensentscheidung zu in-
tegrieren.


1.2.3 Verhaltensverifikation


Die Verifikation geplanter FahrmanÃ¶ver bzw. die Absicherung der Verhaltens-
generierung ist ein noch junges und offenes Forschungsfeld. Bisher werden
diesbezÃ¼glich insbesondere folgende zwei prominente Methodenklassen ver-
folgt: Das Konzept der Verantwortungsbewussten Sicherheit [Sha17] ist dar-
auf ausgelegt zu bewerten, ob ein Verhalten fÃ¼r die jeweilige Situation an-
gemessen und verantwortungsvoll ist. Hierzu formalisiert es Verkehrsregeln,
legt sinnvolle Annahmen fest und definiert Begriffe wie sicherer Abstand, ge-
fÃ¤hrliche Situation, angemessene Reaktion und Verantwortung. Die Autoren zei-
gen zudem, dass es zu keinem Unfall kÃ¤me, wenn sich alle Verkehrsteilneh-
mer an die vorgestellten Regeln hielten. WÃ¤hrend die einzelnen formulier-
ten Regeln sich in einfachen mathematischen Formeln niederschlagen, bildet
das gesamte Konzept einen umfangreichen Katalog an situationsspezifischen
Regeln und Anforderungen an die zeitlichen sowie rÃ¤umlichen AbstÃ¤nde in
Quer- und LÃ¤ngsrichtung, die Fahrzeuggeschwindigkeit und die Beschleuni-
gung. Die Ã¼berwÃ¤ltigende Anzahl an festzulegenden Parametern erschwert
allerdings den Einsatz der Methode.


Ein einheitlicherer Ansatz basiert auf der Erreichbare-Mengen-Analyse und
zielt darauf ab, eine beweisbar sichere sog. Fail-Safe-Trajektorie vorzuhalten,
auf die gewechselt werden kann, sofern eine Kollision droht [Alt16]. Dabei
wird die Fail-Safe-Trajektorie nur dann als sicher eingestuft, wenn sie kei-
ne Ãœberlappung mit den Worst-Case-Belegungen anderer Verkehrsteilneh-
mer hat, also garantiert kollisionsfrei ist. Die Soll-Trajektorie muss hingegen
nur sicherstellen, dass im nÃ¤chsten Planungsintervall noch auf die Fail-Safe-
Trajektorie gewechselt werden kann. Allerdings treffen bisherige Publikatio-
nen teilweise weitreichende Annahmen, die fÃ¼r die reale Anwendung sicher-
lich noch relaxiert werden mÃ¼ssen. Beispielsweise gehen sie davon aus, dass


Fahrzeuge ihren Fahrstreifen â€“ abgesehen von Fahrstreifenwechseln â€“ nicht
verlassen, worauf man gerade in beengten Kreuzungsbereichen nicht vertrau-
en kann, insbesondere wenn keine Fahrbahnmarkierungen vorhanden sind.
Dennoch stellt die Erreichbare-Mengen-Analyse einen hilfreichen Ansatz dar,
u. a. weil er konsistent, anschaulich und zugleich effizient ist. Zudem lÃ¤sst sich
das Konzept der Fail-Safe-Trajektorien sehr gut in eine Verhaltensentschei-
dung mit RÃ¼ckfallebenen integrieren.


1.3 BeitrÃ¤ge der Arbeit


Diese Arbeit schlÃ¤gt eine Methode zur Verhaltensgenerierung fÃ¼r automati-
sierte Fahrzeuge vor, welche bereits innerhalb der Verhaltensentscheidung si-
cherstellt, dass geplante FahrmanÃ¶ver realisierbar und sicher sind. Somit kann
sie bei riskanten ManÃ¶vern oder bei AusfÃ¤llen einzelner Verhaltensoptionen
rechtzeitig eingreifen und auf Alternativoptionen oder RÃ¼ckfallebenen wech-
seln.


Hierzu wird ein Arbitrationsgraph entworfen, dessen Verhaltensbausteine
grundlegende Verhaltenskompetenzen bzw. FahrmanÃ¶ver adressieren und
in Form von Trajektorien ausgeben. Zudem wird das Arbitrationsverfahren
um einen Verifikationsschritt und eine darauf ausgelegte Fehlerbehandlung
erweitert. So wird garantiert, dass die Arbitratoren nur solche Trajektorien
weiterreichen, die die Verifikation bestehen. FÃ¼r die RÃ¼ckfallebene werden
Verhaltensbausteine implementiert, die das vorige ManÃ¶ver fortsetzen, ei-
ne vorgehaltene Plan-B-Trajektorie zurÃ¼ckgeben oder eine Notbremsung
durchfÃ¼hren.


SchlieÃŸlich tragen diese MaÃŸnahmen zu einer robusten und sicheren Verhal-
tensgenerierung bei, die auch auf andere Robotikanwendungen Ã¼bertragbar
ist. Die wesentlichen BeitrÃ¤ge dieser Arbeit sind zusammenfassend:


â€¢ Definition einer Szenario-unabhÃ¤ngigen ManÃ¶verreprÃ¤sentation fÃ¼r
das automatisierte Fahren.


â€¢ Erweiterung des Arbitrationsverfahrens um eine Verifikationslogik, die
sicherstellt, dass nur Verhaltensoptionen ausgefÃ¼hrt werden, welche
einer Verifikation standhalten.


â€¢ Definition dreier Verifikatoren fÃ¼r das automatisierte Fahren, die
potenzielle ManÃ¶ver auf GÃ¼ltigkeit, Realisierbarkeit und
Verkehrssicherheit Ã¼berprÃ¼fen.


â€¢ Entwurf eines Sicherheitskonzepts, um â€“ mittels Verifikation,
EchtzeitfÃ¤higkeit, Redundanz und DiversitÃ¤t â€“ eine robuste und
sichere Verhaltensarbitration zu gewÃ¤hrleisten.


â€¢ Evaluation des vorgeschlagenen Sicherheitskonzepts in einer
anwendungsnahen Simulationsumgebung.


1.4 Ãœberblick


Der restliche Teil der Arbeit ist wie folgt aufgebaut.


In Kapitel 2 wird zunÃ¤chst eine EinfÃ¼hrung in die fÃ¼r diese Arbeit wesent-
lichen Grundlagen gegeben. Im Anschluss beschreiben Kapitel 3 und 4 den
Kern dieser Arbeit: Die Methode der Verhaltensarbitration wird zunÃ¤chst auf
das automatisierte Fahren Ã¼bertragen und anschlieÃŸend zu einem fehlertole-
ranten und sicheren System erweitert. Daraufhin werden in Kapitel 5 grund-
legende FahrmanÃ¶ver zur Befahrung der Karlsruher Teststrecke entworfen
sowie FahrmanÃ¶ver der RÃ¼ckfallebenen definiert, um das Sicherheitskonzept
aus Kapitel 4 zu komplettieren. AnschlieÃŸend prÃ¤sentiert Kapitel 6 den Real-
versuch und Ergebnisse der Evaluation. Zuletzt schlieÃŸt Kapitel 7 die Arbeit
mit einer Diskussion und Zusammenfassung ab.


2 Grundlagen


In diesem Kapitel sind die fÃ¼r diese Arbeit relevanten theoretischen Grundla-
gen gebÃ¼ndelt. ZunÃ¤chst wird die Fahraufgabe in Abschnitt 2.1 modelliert und
gÃ¤ngige Softwarearchitekturen fÃ¼r automatisierte Fahrzeuge vorgestellt. An-
schlieÃŸend fasst Abschnitt 2.2 verwandte Verfahren zur Verhaltensentschei-
dung zusammen, insbesondere die in dieser Arbeit erweiterten Arbitrations-
graphen. Abschnitt 2.3 geht in KÃ¼rze auf die Trajektorienplanung ein, be-
vor sich Abschnitt 2.4 zuverlÃ¤ssigen und fehlertoleranten Systemen widmet.
SchlieÃŸlich wird in Abschnitt 2.5 die Verkehrssicherheit und darin im Spezi-
ellen die Erreichbare-Mengen-Analyse beschrieben.


2.1 Architekturen fÃ¼r automatisierte
Fahrzeuge


Die Fahraufgabe lÃ¤sst sich laut [Mic85] wie in Abb. 2.1 als kaskadierter Regel-
kreis in eine strategische, taktische und operative Ebene gliedern. Die stra-
tegische Ebene definiert allgemeine langfristige PrÃ¤ferenzen und Ziele, u. a.
der geplanten Route. AbhÃ¤ngig von der aktuellen Situation und den zuvor
definierten Zielen werden in der taktischen Ebene FahrmanÃ¶ver umgesetzt,
beispielsweise ein Fahrstreifenwechsel oder ein HaltemanÃ¶ver. Auf der ope-
rativen Ebene wird das beabsichtigte ManÃ¶ver letztlich mit einer Update-
Frequenz in der GrÃ¶ÃŸenordnung von Millisekunden eingeregelt.


Abbildung 2.1: Das 3-Ebenen-Modell nach [Mic85] unterteilt die Fahraufgabe in eine strategi-
sche, taktische und operative Ebene.


Dieses ursprÃ¼nglich menschliche Fahrer beschreibende Modell wird hÃ¤ufig
auch auf die Automatisierung der Fahrfunktion angewandt. Die strategische
Ebene Ã¼bernimmt ein Navigationsmodul. Es bestimmt ausgehend von einem
gegebenen Fahrtziel, meist voreingestellten GÃ¼tekriterien, dem Wegenetz und
ggf. der aktuellen Verkehrslage die Route. Diese wird in Form von Zwischen-
zielen, StraÃŸen oder gar StraÃŸenabschnitten dargestellt. Ein Planungsmodul
bestimmt FahrmanÃ¶ver auf taktischer Ebene mit einem Zeithorizont von et-
wa 5 bis 20 Sekunden. Es bildet die aktuelle Situation einschlieÃŸlich wahr-
genommener Verkehrsteilnehmer unter BerÃ¼cksichtigung der vorgesehenen
Route und vorhandenen Verkehrsregeln auf eine geeignete Soll-Trajektorie
ab. HierfÃ¼r bestimmt es ggf. auch den zu befahrenden Fahrstreifen. Die ope-
rative Ebene wird schlieÃŸlich von der Regelung Ã¼bernommen. Sie setzt die
Soll-Trajektorie in einer hochfrequenten Regelschleife in Aktor-StellgrÃ¶ÃŸen
wie Lenkwinkel und Beschleunigung um.


Die somit gÃ¤ngigsten Architekturen fÃ¼r automatisierte Fahrzeuge legt
Abb. 2.2 dar. Im einfachsten Fall werden die Wahrnehmung, PrÃ¤diktion,
Verhaltensentscheidung, Trajektorienplanung und Regelung in einer entkop-
pelten Verarbeitungskette durchgefÃ¼hrt. FÃ¼r die Planung von interaktivem
Verhalten muss die PrÃ¤diktion hingegen in die Verhaltens- und Trajektori-
enplanung integriert werden. Wird die gesamte Verarbeitungskette in einen
gemeinsamen Verarbeitungsschritt verwoben, wie es beispielsweise in An-
sÃ¤tzen des Maschinellen Lernens hÃ¤ufig zu beobachten ist, spricht man von
Ende-zu-Ende Planung.


2.2 Verhaltensentscheidung


Die Verhaltensentscheidung ist Teil der taktischen Ebene (vgl. Abb. 2.1) bzw.
des Planungsmoduls. Ausgehend von der aktuellen Situation trifft sie die Ent-
scheidung, welches ManÃ¶ver gefahren wird. Dieses gibt sie entweder in Form
von Nebenbedingungen an die nachgelagerte Trajektorienplanung oder,
wenn sie die Trajektorienplanung selbst Ã¼bernimmt, als Soll-Trajektorie an
die Regelung weiter.


In der Literatur haben sich vielfÃ¤ltige Verfahren etabliert, deren Einsatzberei-
che von reiner Verhaltensentscheidung hin zur situationsspezifischen Trajek-
torienplanung Ã¼bergehen. Regelbasierte Verfahren, wie Endliche Zustandsau-
tomaten, EntscheidungsbÃ¤ume oder Arbitrationsgraphen, adressieren die rei-
ne Verhaltensentscheidung durch diskrete Zustands-/Moduswechsel. Graph-
bzw. suchbasierte Verfahren wie A*, Probabilistische StraÃŸenkarten (PRM*)
und Rapidly-exploring Random Trees (RRT*), sind insbesondere in der Pfad-
planung mobiler Roboter beliebt, kÃ¶nnen aber auch zur Entscheidungsfin-
dung eingesetzt werden. In der Trajektorienplanung kommen immer hÃ¤ufiger
probabilistische Methoden, wie POMDPs, sowie Verfahren des Maschinellen
Lernens, u. a. das BestÃ¤rkende Lernen, zum Einsatz. Dabei Ã¼bernehmen sie
teilweise auch implizite Entscheidungen, bspw. wann und in welche LÃ¼cke
ein Fahrstreifenwechsel stattfindet.


In diesem Abschnitt liegt der Fokus auf regelbasierten Verfahren, zu denen
sowohl klassische zustandsbasierte Verfahren wie Endliche Zustandsautoma-
ten (Abschnitt 2.2.1) und EntscheidungsbÃ¤ume (Abschnitt 2.2.2), sowie Verhal-
tensbasierte Verfahren wie VerhaltensbÃ¤ume (Abschnitt 2.2.3) und Arbitrati-
onsgraphen (Abschnitt 2.2.4) zÃ¤hlen. FÃ¼r eine umfangreiche MethodenÃ¼ber-
sicht sei auf [Sch18, Yur20, VoÃŸ21, Gam21] verwiesen. Eine umfangreichere
Fassung dieses Abschnitts erscheint auÃŸerdem in [Orz23].


Regelbasierte Verfahren sind, wie bereits in Abschnitt 1.3 ausgefÃ¼hrt, insbe-
sondere im Kontext der Fahrerassistenzsysteme sowie fÃ¼r den Einsatz von
Versuchsfahrzeugen kleinerer Forschungsgruppen weit verbreitet [Aeb15,
Bac08, Mon08, Zie14a]. Dies lÃ¤sst sich u. a. auf ihre einfache Anwendung, zahl-
reiche frei verfÃ¼gbare Software-Frameworks [Sch14, Bur18, Gre21b, The20b],
einschlieÃŸlich direkter Einbindung in MATLAB [The20a], oder auch deren
Standardisierung in der Unified Modeling Language [Obj17] zurÃ¼ckfÃ¼hren.


2.2.1 Endliche Zustandsautomaten


Endliche Zustandsautomaten, auch als deterministische endliche Automaten
bezeichnet, haben ihren Ursprung im Hardware Design und der Theoretische
Informatik [Wag06, Hop07, Vos16]. Mittlerweile werden sie auch in der Ro-
botik [Sic16] und im Bereich der Fahrerassistenzsysteme eingesetzt [Zie14b,
Aeb15]. Endliche Zustandsautomaten sind leicht zu verstehen und zugleich
sehr einfach zu implementieren.


Dieser Abschnitt fasst die wichtigsten Inhalte aus [Vos16] und [Hop07] zu-
sammen, um eine praxisorientierte EinfÃ¼hrung in die Theorie Endlicher Zu-
standsautomaten zu geben.


Ein Endlicher ZustandsautomatÂ¹ besteht aus


â€¢ einer endlichen Menge an ZustÃ¤nden ğ‘†,


â€¢ einer endlichen Menge an Eingangssymbolen Î£ (oder Ereignissen),


â€¢ einer endlichen Menge an Ausgangssymbolen Î” (oder Aktionen),


â€¢ einer ZustandsÃ¼bergangsfunktion ğ›¿ âˆ¶ ğ‘† Ã— Î£ â†’ ğ‘†,


â€¢ einer Ausgabefunktion ğœ† âˆ¶ ğ‘† â†’ Î”,


â€¢ einem Anfangszustand ğ‘  âˆˆ ğ‘† und 0


â€¢ einer endlichen Menge an EndzustÃ¤nden ğ¹ âŠ† ğ‘†.


Ein Endlicher Zustandsautomat beginnt zunÃ¤chst in dem Anfangszustand ğ‘  . 0
Bei jedem, in der Regel von auÃŸen eingehenden, Ereignis ğ‘’ âˆˆ Î£ wechselt er ğ‘–
in einen neuen Zustand ğ‘  = ğ›¿(ğ‘  , ğ‘’ ). Dabei kann der neue Zustand auch ğ‘–+1 ğ‘– ğ‘–
als derselbe Zustand ğ‘  = ğ‘  festgelegt sein. Nach jedem Zustandswechsel ğ‘–+1 ğ‘–
in einen Zustand ğ‘  gibt der Zustandsautomat die Ausgabe ğ‘ = ğœ†(ğ‘  ) aus. Ein- ğ‘– ğ‘– ğ‘–
zelne ZustÃ¤nde kÃ¶nnen in Erweiterungen wie den Hierarchischen Zustands-
automaten wiederum selbst Zustandsautomaten sein oder auch nebenlÃ¤ufige
Zustandsautomaten enthalten.


In der Robotik allgemein decken ZustÃ¤nde i. d. R. einzelne Verhaltensmodi ab,
sodass ihre Ausgaben, die geplante Aktion, als Stell- oder ZielgrÃ¶ÃŸen an die
ausfÃ¼hrende Schicht weitergegeben werden. Die Ereignisse des Zustandsau-
tomaten werden meist von einer Situationsinterpretation erzeugt, um ggf. ei-
nen Wechsel des Verhaltensmodus einzuleiten.


Bspw. setzte das Team Junior der UniversitÃ¤t Stanford Endliche Zustandsauto-
maten erfolgreich in der DARPA Urban Challenge ein [Mon08]. Wie in Abbil-
dung 2.3 veranschaulicht, stellen hierbei die ZustÃ¤nde taktische FahrmanÃ¶ver
wie Weiterfahrt, Passieren einer Kreuzung oder Einparken ab. Im Sinne ei-
ner besseren Ãœbersichtlichkeit wurden allerdings zwei ZustÃ¤nde (Escape und
Traffic Jam) ausgelassen, weil sie von fast allen Ã¼brigen ZustÃ¤nden aus er-
reichbar sind.


FOOTNOTE:Â¹ In dieser Arbeit wird die Moore-Notation verwendet. Alternativ lÃ¤sst sich die Notation auch in
das sog. Mealy-Modell Ã¼berfÃ¼hren.


FÃ¼r Ã¼berschaubare Verhaltensprobleme sind Endliche Zustandsautomaten
aufgrund ihrer einfachen Umsetzung und intuitiven Darstellung eine gute
Wahl. Da die Anzahl mÃ¶glicher ZustandsÃ¼bergÃ¤nge allerdings im schlimms-
ten Fall quadratisch mit der Anzahl der ZustÃ¤nde wÃ¤chst, skalieren sie bei
komplexeren Systemen schlecht. Dieses Wachstum kÃ¶nnen Hierarchische
Zustandsautomaten zumindest auf manuell definierte hierarchische Ebenen
begrenzen.


Die schlechte Modifizierbarkeit ist ein weiterer Nachteil von Endlichen Zu-
standsautomaten: Beim HinzufÃ¼gen oder Entfernen von ZustÃ¤nden mÃ¼ssen
ggf. viele der bereits vorhandenen ZustÃ¤nde und ZustandsÃ¼bergÃ¤nge in Be-
tracht gezogen und mit angepasst werden.


Die ZustandsÃ¼bergÃ¤nge in Endlichen Zustandsautomaten gleichen auÃŸerdem
Sprunganweisungen, die es erschweren Quellcode zu verstehen, zu analysie-
ren oder zu verifizieren. Um nachzuvollziehen, warum ein bestimmter Zu-
stand aktuell aktiv ist, muss folglich eine Ereignishistorie erstellt und aufwen-
dig Schritt fÃ¼r Schritt nachvollzogen werden. Daher werden Goto Befehle in


der Softwareentwicklung spÃ¤testens seit EinfÃ¼hrung Strukturierter Program-
miersprachen weitgehend vermieden [Dij68, Dah72].


Bei der Visualisierungen von Zustandsautomaten komplexerer Systeme leidet
schlieÃŸlich die Ãœbersichtlichkeit an der groÃŸen Zahl an ZustandsÃ¼bergÃ¤ngen.
In Abb. 2.3 sah sich Team Junior daher sogar gezwungen, zwei stark vernetzte
ZustÃ¤nde auszulassen.


2.2.2 EntscheidungsbÃ¤ume


EntscheidungsbÃ¤ume wurden ursprÃ¼nglich als rekursive Strukturen zur Be-
schreibung von Klassifikationsregeln entworfen [Mor82, Qui90]. Formal wer-
den sie als gerichtete geordnete BÃ¤ume formuliert. Die Knoten bilden da-
bei Bedingungen in Form diskreter oder gar boolescher Entscheidungsva-
riablen ğ‘¥ ab, wÃ¤hrend die BlÃ¤tter die daraus resultierenden Entscheidungen ğ‘–
ğ‘“(ğ‘¥ , â€¦ ,ğ‘¥ ) reprÃ¤sentieren. Die Auswertung beginnt am Wurzelknoten und 1 ğ‘›
wird, je nach Wert seiner Entscheidungsvariable ğ‘¥ = ğ‘˜ am ğ‘˜-ten Kindkno- ğ‘–
ten, rekursiv fortgesetzt bis ein Blatt erreicht wird und somit die Entscheidung
feststeht.


In der Praxis werden EntscheidungsbÃ¤ume hÃ¤ufig als hierarchische Verket-
tung von if/else Verzweigungen realisiert. Daher erfreuen sie sich in Ã¼ber-
schaubaren Entscheidungsproblemen groÃŸer Beliebtheit.


Zum Einsatz in Fahrerassistenzsystemen wird i. d. R. eine geeignete Zustands-
raumdarstellung gewÃ¤hlt, die anschlieÃŸend mit den Entscheidungsvariablen
geeignet unterteilt wird [Ard10]. Abbildung 2.4 stellt bspw. zwei Entschei-
dungsbÃ¤ume dar, die von BMW â€“ in Kombination mit Endlichen Zustandsau-
tomaten â€“ fÃ¼r hochautomatisiertes Fahren auf Autobahnen und einen Nothal-
teassistenten eingesetzt wurde [Ard11]. Hierbei wurden zwei separate Ent-
scheidungsbÃ¤ume, jeweils fÃ¼r die Quer- und LÃ¤ngsfÃ¼hrung, entworfen. Die
Entscheidungsvariablen wurden beispielsweise als Spurwechselwunsch aus
der Situationsinterpretation abgeleitet. SchlieÃŸlich gaben die BlÃ¤tter SollgrÃ¶-
ÃŸen und Nebenbedingungen fÃ¼r die nachgelagerte Trajektorienplanung vor.


Vergleichbar zu Endlichen Zustandsautomaten sind EntscheidungsbÃ¤ume ein-
fach zu implementieren und intuitiv begreifbar. Ein weiterer Vorteil ist die
ModularitÃ¤t und Erweiterbarkeit: TeilbÃ¤ume kÃ¶nnen unabhÃ¤ngig vom Rest
des Baumes entworfen, entwickelt und in den Entscheidungsbaum hinzuge-
fÃ¼gt werden kÃ¶nnen. Die BlÃ¤tter geben allerdings keinerlei (Erfolgs-)Status
oder anderweitige Leistungskriterien zurÃ¼ck, sodass das Resultat eines Ver-
haltens die weitere Verhaltensauswahl nicht direkt beeinflussen kann.


2.2.3 VerhaltensbÃ¤ume


VerhaltensbÃ¤ume wurden zunÃ¤chst in der Computerspiel-Entwicklung ent-
worfen [Iov22] und sind seit 2012 immer hÃ¤ufiger auch in Robotikanwendun-
gen im Einsatz [Bag12, Ã–gr12]. Im Bereich der Fahrerassistenzsysteme oder
automatisierten Fahrzeuge wurde hingegen bisher nur eine Arbeit publiziert
[Ols16]. Sie untersucht die Ãœberlegenheit von VerhaltensbÃ¤umen gegenÃ¼ber
Endlichen Zustandsautomaten in Simulation, indem sie die Skalierbarkeit bei-
der Methoden mit Softwaremetriken vergleicht. Eine ausfÃ¼hrliche Ãœbersicht
und EinfÃ¼hrung in VerhaltensbÃ¤ume liefern [Iov22, Col18]. Dieser Abschnitt
soll jedoch eine kurze praxisorientierte EinfÃ¼hrung in die Methodik geben.


VerhaltensbÃ¤ume zeichnen sich zunÃ¤chst durch eine strikte funktionale
Trennung zwischen Verhaltensentscheidung und -ausfÃ¼hrung aus. Formal
betrachtet sind sie zusammenhÃ¤ngende kreisfreie ungerichtete Graphen,
dessen innere Knoten (sog. Kontrollfluss-Knoten) den Selektionsmechanismus
festlegen, wÃ¤hrend die BlÃ¤tter mÃ¶gliche Verhalten (sog. Aktions-Knoten)
sowie Bedingungen (sog. Bedingungs-Knoten) beschreiben.


Ausgehend vom Wurzelknoten wird der Baum mit einer festgelegten Fre-
quenz, Ã¤hnlich einer Tiefensuche, ausgewertet. Dabei gibt ein ausgewerte-
ter Knoten Ã¼ber seinen RÃ¼ckgabewert an, ob er noch ausgefÃ¼hrt wird, er-
folgreich abgeschlossen wurde oder fehlgeschlagen ist. Je nach RÃ¼ckgabe-
wert wertet der Ã¼bergeordnete Kontrollfluss-Knoten weitere Kindknoten aus
oder gibt seinen eigenen Status zurÃ¼ck. Dabei stehen verschiedene Arten von
Kontrollfluss-Knoten zur VerfÃ¼gung, u. a. zur Realisierung von Sequenzen,
Fallback-Strukturen und NebenlÃ¤ufigkeit.


Wird ein Bedingungs-Knoten ausgewertet, gibt er Ã¼ber seinen RÃ¼ckgabewert
zurÃ¼ck, ob die zugrundeliegende Bedingung erfÃ¼llt ist, ohne selbst Einfluss
auf die Umwelt zu nehmen. Aktions-Knoten fÃ¼hren bei einem Aufruf hin-
gegen das entsprechende Verhalten aus und geben Ã¼ber ihren RÃ¼ckgabewert
den Status dieses Verhaltens zurÃ¼ck. Die Aktions-Knoten beschreiben folglich
die einzelnen Verhaltensoptionen eines Systems, wÃ¤hrend ihre Vorbedingun-
gen Ã¼ber Bedingungs-Knoten modelliert werden. Durch die Unterscheidung
zwischen Bedingungs- und Aktions-Knoten, sind die Vorbedingungen eines


Verhaltens allerdings von der eigentlichen AusfÃ¼hrung des Verhaltens ent-
koppelt.


Als Beispiel veranschaulicht Abb. 2.5 einen Verhaltensbaum eines interakti-
ven humanoiden Unterhaltungs-Roboters (vereinfacht aus [Col18]). Der Ro-
boter soll sich nach Aufforderung des Bedieners setzen, aufstehen, Ball spielen
oder sich verabschieden. Jede Aktion wird hierbei Ã¼ber einen Sequenz-Knoten
mit ihrem korrespondierenden Bedingungs-Knoten, welcher zurÃ¼ckgibt, ob
diese Aktion ausgefÃ¼hrt werden soll, verknÃ¼pft. Bspw. hÃ¤ngt die Aktion Stand
Up von der Bedingung Activity Stand Up ab.


Abbildung 2.5: Verhaltensbaum fÃ¼r einen interaktiven humanoiden Roboter (angepasst aus
[Col18]). Runde BlÃ¤tter stellen die Bedingungs-Knoten und eckige BlÃ¤tter die
Aktions-Knoten dar. Sequenz-Knoten sind als Pfeil (â†’), Fallback-Knoten mit ei-
nem Fragezeichen (?) und NebenlÃ¤ufigkeits-Knoten mit einem Doppelpfeil (â‡‰)
gekennzeichnet.


Im Kontext der Fahrerassistenzsysteme oder des automatisierten Fahrens
kÃ¶nnten Aktions-Knoten FahrmanÃ¶ver wie Folgefahrt, Fahrstreifenwechsel


oder Einparken realisieren. Um ein sicheres System zu entwerfen, mÃ¼ssten
sie allerdings mit zuverlÃ¤ssigen Bedingungs-Knoten verknÃ¼pft werden.


Zusammenfassend generalisieren VerhaltensbÃ¤ume viele andere Architektu-
ren wie Hierarchische Endliche Zustandsautomaten und EntscheidungsbÃ¤u-
me [Col17], bieten diesen gegenÃ¼ber allerdings viele Vorteile: Sie Ã¼berzeu-
gen insbesondere durch ModularitÃ¤t, hierarchische Anordnung, Wiederver-
wendbarkeit der Komponenten, Reaktionsschnelligkeit und Interpretierbar-
keit [Col18]. Im Vergleich zu Endlichen Zustandsautomaten ist vor allem die
grÃ¶ÃŸere FlexibilitÃ¤t vorteilhaft. Einzelne Verhalten kÃ¶nnen innerhalb eines
Verhaltensbaums (wieder-)verwendet werden ohne spezifizieren zu mÃ¼ssen,
welchen Bezug sie zu den anderen Verhaltensoptionen haben [Bag12]. In der
grafischen Darstellung ist der Selektionsmechanismus eines Verhaltensbaums
zudem intuitiv sehr gut erfassbar und auch im Online-Betrieb leicht nachvoll-
ziehbar. Andererseits kann die Darstellung in der Praxis doch sehr umfang-
reich werden, da hÃ¤ufig jede Vorbedingung als separater Blattknoten model-
liert wird. Die Sicherheit des Systems hÃ¤ngt auÃŸerdem, durch die erwÃ¤hnte
Entkopplung von Vorbedingungen und AusfÃ¼hrung eines Verhaltens, maÃŸ-
geblich von der Anordnung der Knoten im Baum ab. Diese Nachteile werden
von den Arbitrationsgraphen im folgenden Abschnitt adressiert.


2.2.4 Arbitrationsgraphen


Das Konzept der Verhaltensarbitration ist im Kontext des RoboterfuÃŸballs
entstanden und kombiniert Ideen aus Brooksâ€™ verhaltensbasierter Subsumpti-
on [Bro86], wissensbasierten Architekturen wie Belief-Desire-Intention (BDI)
[Rao92] und Programmierparadigmen wie der Objektorientierten Program-
mierung [Ste85]. Es wurde ausfÃ¼hrlich in [Lau10] beschrieben und wird in
diesem Abschnitt am selben Beispiel, dem RoboterfuÃŸball, zusammengefasst.


FuÃŸball ist durch eine sich hochdynamisch verÃ¤ndernde Umwelt und zugleich
etablierte Spieltaktiken und -strategien fÃ¼r Angreifer, Verteidiger und TorhÃ¼-
ter gekennzeichnet. Daher wurde fÃ¼r die Anwendung im RoboterfuÃŸball eine
Architektur gesucht, die es ermÃ¶glicht geringe Reaktionszeiten zu erreichen,
bekannte Spieltaktiken aus einfachen Teilbausteinen zusammenzusetzen und


dabei deliberative Komponenten mit AnsÃ¤tzen des Maschinellen Lernens zu
kombinieren. Es sollte somit ein modulares Software-Framework entwickelt
werden, das inkrementell erweiterbar ist, sich durch klare Schnittstellen aus-
zeichnet und schlieÃŸlich zu einem transparenten Entscheidungsprozess fÃ¼hrt.


Das Konzept setzt auf atomare Verhaltensbausteine, die einfache FÃ¤higkei-
ten und Verhaltensweisen abbilden. Diese werden nach Subsumptions-Prinzip
mittels Arbitratoren zu komplexerem Systemverhalten, also Taktiken bis hin
zu Strategien, kombiniert. Statt ein Problem also im wissensbasierten Top-
Down Ansatz zu Teilproblemen zu zerlegen, wird komplexes Verhalten im
Bottom-Up Entwurf iterativ aus einfachen Verhaltenskompetenzen zusam-
mengesetzt.


Im RoboterfuÃŸball gibt es bspw. Verhaltensbausteine zum Dribbeln, Ziel an-
steuern oder SchieÃŸen. In Kombination realisieren sie komplexeres Verhalten
â€” von simpleren Taktiken wie einem Flankenangriff oder Doppelpass bis hin
zu ganzen Angriffs- oder Verteidigungs-Strategien in hÃ¶heren Abstraktions-
ebenen.


Als Eingang dient den Verhaltensbausteinen die aktuelle Situation ğ’” des Um-
felds in Form von sensornahen Messdaten oder einem abstrahierten bis hin
zu interpretierten Umweltmodell. Diese werden mit der Stellfunktion Aktion
auf aktornahe StellgrÃ¶ÃŸen ğ’– abgebildet:


Im RoboterfuÃŸball besteht ğ’– bspw. aus der gewÃ¼nschten LÃ¤ngs- und Winkel-
geschwindigkeit eines Spielers sowie aus Anweisungen fÃ¼r seine Schussvor-
richtung. Um dabei nicht nur reaktives, sondern auch deliberatives Verhalten
zu ermÃ¶glichen, kÃ¶nnen die Verhaltensbausteine Situations- und Befehlshis-
torien anlegen oder randomisierte Verfahren nutzen.


Jeder Verhaltensbaustein bestimmt, neben seiner eigentlichen Aktion, Ã¼ber die
sogenannte Start-Bedingung Start auch, ob seine Vorbedingungen erfÃ¼llt
sind und das Verhalten somit aktuell Ã¼berhaupt anwendbar ist. Ein FuÃŸball-
spieler kann den Ball bspw. nur dann in Richtung Tor dribbeln, wenn er auch
tatsÃ¤chlich in Ballbesitz ist. Ist ein Verhaltensbaustein aktiv, gibt er Ã¼ber die


Algorithmus 1 : Generisches Arbitrationsverfahren


1 function BesteAnwendbareAktion(Situation ğ’”)


FOOTNOTE:2 Filtere anwendbare Optionen ğ’œ âŠ‚ ğ’ª


FOOTNOTE:3 WÃ¤hle Intention ğœƒ âˆˆ ğ’œ aus


// Arbitration


FOOTNOTE:4 Bestimme ğ’– = Aktionğœƒ(ğ’”)


8 while true do


FOOTNOTE:9 Bestimme die aktuelle Situation ğ’”


10 BBeessttiimmmmee dğ’–ie=akBteusetlleeASnitwueantidobnareAktion(ğ’”)


Fortsetzungs-Bedingung Fortsetzung auÃŸerdem zurÃ¼ck, ob alle Bedingun-
gen erfÃ¼llt sind, um das Verhalten weiterhin fortzufÃ¼hren. Denn der Spieler
kann nur so lange weiter dribbeln, bis er den Ball verliert oder das Dribbelziel
erreicht hat. Ãœber die Start- und Fortsetzungs-Bedingung bestimmt jeder Ver-
haltensbaustein also selbst, ob er in der gegebenen Situation anwendbar ist.
Daher benÃ¶tigt die aufrufende Instanz selbst kein Wissen Ã¼ber die Vorausset-
zungen zum AusfÃ¼hren eines Verhaltensbausteins.


Generische Arbitratoren stellen eine Menge an Verhaltensbausteinen, an die-
ser Stelle auch als Optionen ğ’ª bezeichnet, zu einer Taktik zusammen. Al-
gorithmus 1 beschreibt das Arbitrationsverfahren im Allgemeinen. ZunÃ¤chst
wird also die aktuelle Situation ğ’” aus den aktuellsten Eingangsdaten bestimmt
(Zeile 9) und den Verhaltensbausteinen zur VerfÃ¼gung gestellt. Als NÃ¤chstes
bestimmt der Arbitrator seine beste anwendbare Aktion. Hierzu filtert er aus
seinen Optionen ğ’ª jene Optionen ğ’œ heraus, die aktuell anwendbar sind bzw.
in deren DomÃ¤ne die aktuelle Situation fÃ¤llt. Dies signalisieren die Verhaltens-
bausteine Ã¼ber ihre Start- und Fortsetzungs-Bedingung:


Aus den anwendbaren Optionen ğ’œ wÃ¤hlt der Arbitrator schlieÃŸlich die best-
mÃ¶gliche Option aus, definiert sie als seine Intention ğœƒ und fÃ¼hrt diese aus.


FÃ¼r die eigentliche Arbitration, also die Bestimmung der bestmÃ¶glichen Opti-
on, kommen unterschiedliche Schemata infrage. Ein PrioritÃ¤ts-Arbitrator hÃ¤lt
seine Optionen in einer nach PrioritÃ¤t sortierten Liste und wÃ¤hlt daraus in
jeder Iteration die erstbeste anwendbare Option. Der Abschluss-Arbitrator
nutzt ebenfalls eine PrioritÃ¤tenliste, stellt allerdings sicher, dass eine aktive
Option nicht durch eine hÃ¶her priorisierte Option unterbrochen wird, solan-
ge ihre Fortsetzungs-Bedingung wahr ist. Bei dem Zufalls-Arbitrator wird die
Auswahl, mit ggf. gewichteten Wahrscheinlichkeiten, zufÃ¤llig gefÃ¤llt. Der Se-
quenz-Arbitrator dient schlieÃŸlich dazu, Verhaltensoptionen sequenziell ab-
zuarbeiten. Hierzu fÃ¼hrt er seine aktuelle Intention so lange aus, bis ihre Fort-
setzungs-Bedingung nicht mehr zutrifft. Ist gleichzeitig die Start-Bedingung
der nÃ¤chsten Option wahr, wird diese zur neuen Intention und ausgefÃ¼hrt.


Bei allen Arbitrationsschemata hÃ¤ngt die Start- und Fortsetzungs-Bedingung
eines Arbitrators ausschlieÃŸlich von den Start- und Fortsetzungs-Bedingun-
gen seiner Optionen ab. Die Start-Bedingung des PrioritÃ¤ts-, Abschluss- und
Zufalls-Arbitrators ist zum Zeitpunkt ğ‘˜ bspw. dann wahr, solange eine seiner
Optionen eine wahre Start-Bedingung hat:


Der Sequenz-Arbitrator hat hingegen genau dann eine wahre Start-Bedin-
gung, wenn seine erste Option ğ‘œ eine wahre Start-Bedingung hat: 1


Die Fortsetzungs-Bedingung eines Arbitrators zeigt wie bei den Verhaltens-
bausteinen an, ob er in der aktuellen Situation fortgesetzt werden kann. Bei
den meisten Arbitratoren trifft dies bereits dann zu, wenn eine ihrer Optio-
nen ğ’ª eine wahre Start-Bedingung hat oder die letzte Intention ğœƒ fortge- ğ‘˜âˆ’1
setzt werden kann. Dies trifft fÃ¼r den PrioritÃ¤ts, Abschluss und Zufalls-Ar-
bitrator zu:


Beim Sequenz-Arbitrator hÃ¤ngt die Fortsetzungs-Bedingung wiederum von
seiner letzten Intention ğœƒ und der in ğ’ª darauf folgenden Option ğœƒ +1 ab: ğ‘˜âˆ’1 ğ‘˜âˆ’1


Fortsetzung (ğ’” ) = Fortsetzung (ğ’” ) âˆ¨ Start (ğ’” ) (2.7) seq ğ‘˜ ğœƒğ‘˜âˆ’1 ğ‘˜ ğœƒğ‘˜âˆ’1+1 ğ‘˜


Es ist an dieser Stelle hervorzuheben, dass die Arbitratoren ihre Wahl also
nicht situationsspezifisch, sondern rein auf Basis der abstrakten Start- und
Fortsetzungs-Bedingungen der Verhaltensoptionen treffen. Gegeben einer
Menge anwendbarer Optionen ğ’œ, wÃ¤hlt ein Arbitrator seine Intention ğœƒ
also ohne BerÃ¼cksichtigung der Situation ğ’” aus. Dadurch wird eine starke
Entkopplung der Situationsinterpretation und der Auswahllogik erreicht.
Erstere wird Ã¼ber die Start- und Fortsetzungs-Bedingungen ausschlieÃŸlich
in den Verhaltensbausteinen durchgefÃ¼hrt und letztere vollstÃ¤ndig von den
Arbitratoren Ã¼bernommen. Damit bleiben die Arbitratoren anwendungsun-
abhÃ¤ngig wÃ¤hrend die Verhaltensbausteine szenariospezifische LÃ¶sungen
realisieren kÃ¶nnen.


Um nun aus einfachen Verhaltensoptionen und Ã¼berschaubaren Taktiken
komplexe Strategien zu entwerfen, kÃ¶nnen Arbitratoren und Verhaltensbau-
steine zu einem hierarchischen Graphen zusammengestellt werden. Hierzu
gleichen Arbitratoren hinsichtlich ihrer Schnittstelle den Verhaltensbaustei-
nen und kÃ¶nnen somit auch als solche interpretiert werden: Sie geben Ã¼ber
ihre Start- und Fortsetzungs-Bedingungen an, ob sie in der aktuellen Situa-
tion ğ’” anwendbar sind, und bilden diese Ã¼ber die Stellfunktion Aktion auf
StellgrÃ¶ÃŸen ğ’– ab. Auf den Algorithmus 1 Ã¼bertragen, entspricht die Aktion-
Funktion eines Arbitrators der BesteAnwendbareAktion(ğ’”) Funktion in
Zeile 1. Dies ermÃ¶glicht es, einen Arbitrator wiederum als Verhaltensoption
eines anderen Arbitrators einzusetzen.


Abbildung 2.6: Beispiel fÃ¼r einen hierarchischen Arbitrationsgraphen eines Angreifers im Ro-
boterfuÃŸball.AktuellnichtausfÃ¼hrbareVerhaltensoptionensindgrauhinterlegt,
wÃ¤hrend die gewÃ¤hlte Option grÃ¼n hervorgehoben ist.


Abbildung 2.6 zeigt beispielhaft einen zweistufigen Arbitrationsgraphen fÃ¼r
einen Angreifer im RoboterfuÃŸball. Im FlieÃŸtext werden Verhaltensbausteine
mit Kursiver Schrift und Arbitratoren mit KAPITAL SCHRIFT gekennzeichnet.
Die Taktik ANGREIFEN besteht aus den sequenziell geschalteten Verhaltensop-
tionen Zum Tor Dribbeln und SchieÃŸen. Diese wird in der Gesamtstrategie des
Angreifers (ANGRIFF STRATEGIE) mit hÃ¶chster PrioritÃ¤t ausgefÃ¼hrt. Ist ein An-
griff jedoch nicht mÃ¶glich, soll sich der Angreifer Dem Ball NÃ¤hern oder, falls
auch dies nicht mÃ¶glich oder sinnvoll ist, an seiner Spielposition Patrouillieren.


Viele Vorteile von Arbitrationsgraphen werden insbesondere im Entwurfs-
prozess, der Wartung sowie der Weiterentwicklung einer darauf aufbauenden
Verhaltensentscheidung deutlich. Zum einen kÃ¶nnen die Verhaltensbausteine
dank der bereits erwÃ¤hnten Entkopplung von Situationsinterpretation und
Auswahllogik, voneinander unabhÃ¤ngig entworfen, entwickelt und getestet
werden. Hierzu mÃ¼ssen lediglich die Start- und Fortsetzungs-Bedingungen
spezifiziert und die Stellfunktion definiert werden. Erst in einem nachgelager-
ten Schritt werden die vorhandenen Verhaltensbausteine unter BerÃ¼cksich-
tigung von anwendungsspezifischem Wissen mittels geeigneter Arbitratoren
hierarchisch in einem Graphen angeordnet. Stellt sich zu einem spÃ¤teren Zeit-
punkt zudem heraus, dass noch weitere Verhaltensbausteine notwendig sind,
kÃ¶nnen auch diese unabhÃ¤ngig entwickelt und in den Graphen eingefÃ¼gt wer-
den, ohne die bereits vorhandenen Bausteine anpassen zu mÃ¼ssen. Auch bei
einer umfassenden Rekonfiguration des Graphen bleiben die Verhaltensbau-
steine i. d. R. unberÃ¼hrt.


Der modulare Aufbau der Arbitrationsgraphen bildet zugleich eine optimale
Grundlage, um MaÃŸnahmen zur Robustifizierung und Absicherung des Aus-
wahlprozesses umzusetzen. So wird die Arbitration in Abschnitt 4.2 um eine
Verifikation der StellgrÃ¶ÃŸen und RÃ¼ckfallebenen erweitert. Zudem kÃ¶nnten
Metriken zum Systemzustand einbezogen werden, um auch bspw. im Fall von
SensorstÃ¶rungen in defensiveres Verhalten zu wechseln [TaÅŸ17].


2.3 Trajektorienplanung


Zweck der Trajektorienplanung ist es, ausgehend vom aktuellen Zustand,
bspw. in Form eines geschÃ¤tzten Umweltmodells, eine Trajektorie zu gene-
rieren, die ein gewÃ¼nschtes Verhalten bzw. ManÃ¶ver realisiert. Dabei kÃ¶nnen
Trajektorien in kontinuierlicher oder diskreter Form modelliert werden
(Definitionen 2.1 und 2.2).


Definition 2.1: Kontinuierliche Trajektorie


Eine Trajektorie beschreibt den zeitlichen Verlauf eines Zustands ğ’™ âˆˆ â„ğ‘› Ã¼ber einen
Zeithorizont ğ‘¡ âˆˆ [ğ‘¡ ,ğ‘¡ ]: 0 â„


Definition 2.2: Diskrete Trajektorie


In der diskreten Darstellung, die u.a. in numerischen Verfahren zur Trajektorien-
planung Anwendung findet, wird eine Trajektorie durch ihre ğ‘ âˆˆ â„• diskreten 0
StÃ¼tzpunkte beschrieben:


Beispiel 2.1: Trajektorie eines Fahrzeugs in 2D


Eine Fahrzeugtrajektorie lÃ¤sst sich in Kartesischen Koordinaten mittels Position
(ğ‘¥,ğ‘¦) und Orientierung ğœ™ modellieren [Wer17]:


Im automatisierten Fahren beschreiben Trajektorien i. d. R. die Kartesischen
Koordinaten ğ‘¥, ğ‘¦ eines Fahrzeuges sowie seine Orientierung ğœ™ (Beispiel 2.1).


Da echtzeitfÃ¤hige Methoden zur Trajektorienplanung zumeist nur lokale
LÃ¶sungen liefern, wird hÃ¤ufig die ManÃ¶verentscheidung von der Trajektori-
enplanung getrennt. Die ManÃ¶ver- oder auch Verhaltensentscheidung wÃ¤hlt
zunÃ¤chst die erfolgversprechendste Homotopieklasse aus (siehe dazu auch
[Ben15]) und bestimmt ggf. eine grobe zugehÃ¶rige Referenztrajektorie. Beim
automatisierten Fahren beschreibt eine solche Homotopieklasse bspw. ob
und in welche LÃ¼cke ein Fahrstreifenwechsel vorgenommen werden soll.


Zur Trajektorienplanung selbst bieten sich schlieÃŸlich vielfÃ¤ltige Methoden
an, darunter fallen u. a. Graphensuchverfahren, probabilistische Methoden,
direkte Optimierung, ModellprÃ¤diktive Regelung sowie AnsÃ¤tze des Maschi-
nellen Lernens. Die Methoden arbeiten entweder direkt in Kartesischen Koor-
dinaten oder den sog. Frenet-Koordinaten (Definition 2.3). Einige AnsÃ¤tze pla-
nen zudem zunÃ¤chst die Querbewegung in Form eines Sollpfades und danach
die LÃ¤ngsbewegung entlang dieses Pfades, wÃ¤hrend andere die Quer- und
LÃ¤ngsplanung gemeinsam lÃ¶sen (auch als 2D Trajektorienplanung bezeichnet).


Definition 2.3: Trajektorie in Frenet Koordinaten


Trajektorien kÃ¶nnen â€“ z.B. zur entkoppelten Quer- und LÃ¤ngsplanung â€“ in den sog.
Frenet Koordinaten [Car16], also abhÃ¤ngig von der BogenlÃ¤nge ğ‘  entlang einer Re-
ferenzkurve mit Normalenvektor ğ’ , angegeben werden [Wer10]: ğ‘Ÿ


wobei ğ’“ den LotfuÃŸpunkt entlang der Referenzkurve und ğ‘‘ den orthogonalen Versatz
dazu beschreibt.


Im Folgenden werden nur die fÃ¼r diese Arbeit relevanten Methoden beschrie-
ben. FÃ¼r eine umfassende Ãœbersicht zur ManÃ¶verentscheidung und Trajek-
torienplanung sei u. a. auf [Pad16, Gon16, Wer17, Sch18, Kir21] verwiesen.


2.3.1 Pfadplanung


Wird die Trajektorienplanung in eine Quer- und LÃ¤ngskomponente ent-
koppelt, bestimmt die Pfadplanung dabei die QuerfÃ¼hrung des Fahrzeugs.
Auch hierfÃ¼r kommen vielfÃ¤ltige Verfahren infrage: Im Freiraum, wie bspw.
ParkflÃ¤chen, werden hÃ¤ufig Graphensuchverfahren mit kinematischen Bewe-
gungsmodellen verwendet [Ban18], wÃ¤hrend in Szenarios mit Fahrstreifen
u. a. Dynamische Programmierung [Wer10] oder auch Optimierung [Gut17]
zum Einsatz kommt. Solange keine Hindernisse in den Fahrkorridor hinein-
ragen, kann auch schlicht die Mittellinie eines Fahrstreifens â€“ ggf. mittels
Splines interpoliert â€“ als Referenzpfad genutzt werden.


Abbildung 2.7: Die Pfadplanung bestimmt die QuerfÃ¼hrung eines Fahrzeugs unter BerÃ¼cksich-
tigung der Fahrbahnbegrenzung und hineinragenden Hindernissen. Die Opti-
mierungsachsen sind in Orange dargestellt, der geplante Pfad in GrÃ¼n.


Abbildung 2.7 veranschaulicht beispielhaft die Pfadplanung mittels Optimie-
rung. Die gelben Querbalken bilden die Optimierungsvariablen ab, wÃ¤hrend
in Blau der resultierende Pfad dargestellt ist. Hierbei wurde folgende, aus
[Zie14a] inspirierte, Kostenfunktion verwendet (vgl. Gleichung (2.15)):


wobei ğ‘— das Ãœberschreiten der Fahrstreifenbegrenzungen, ğ‘— die Abwei- bor pos
chung zur Fahrstreifenmitte und ğ‘— die LÃ¤nge des Pfades bestrafen. Durch die len
Einpreisung von ğ‘— und ğ‘— werden zudem KrÃ¼mmung und KrÃ¼mmungs- cur dcur
Ã¤nderung minimiert.


2.3.2 Intelligent Driver Model


Das Intelligent Driver Model (IDM) [Tre00] ist ein mikroskopisches Ver-
kehrsflussmodell, das das LÃ¤ngsverhalten von Fahrern bei der Folgefahrt
beschreibt. Es kann, in Kombination mit einer vorgeschalteten Pfadplanung,
als Folgefahrt-Regler oder gar zur Planung von Folgefahrt-Trajektorien
verwendet werden:


wobei ğ‘£ und ğ‘£ die Geschwindigkeit des Egofahrzeugs und Referenzob- ego obj
jekts, ğ‘‘ den Abstand, Î”ğ‘£ die Geschwindigkeitsdifferenz, ğ‘£ , ğ‘ und ğ‘ die des max cmf
Wunschgeschwindigkeit, Maximalbeschleunigung und komfortable Brems-
beschleunigung, ğ‘‡ den zeitlichen Wunschabstand (engl. â€time headwayâ€œ) und
ğ‘‘ den gewÃ¼nschten Minimalabstand bezeichnet. Der Beschleunigungsex- min
ponent wird typischerweise auf ğ›¿ = 4 gesetzt.


2.3.3 Nichtlineare Optimierung


Bei der 2D-Trajektorienplanung mittels Nichtlinearer Optimierung wird ein,
meist diskretes, nichtlineares Optimierungsproblem formuliert und mittels
numerischer Methoden gelÃ¶st [Wer17]. Hierbei wird die Kostenfunktion ğ½,


unter BerÃ¼cksichtigung von ğ‘š Ungleichungs- und ğ‘ Gleichungsnebenbedin-
gungen ğ’ˆ und ğ’‰, minimiert:


Typische Kostenfunktionen umfassen die Abweichung zum Referenzpfad
(bspw. die Fahrstreifenmitte) sowie der Sollgeschwindigkeit und bestrafen
Beschleunigung, Ruck und Drehrate [Zie14a]:


Um eine erfolgreiche Optimierung zu ermÃ¶glichen, mÃ¼ssen die Kostenfunk-
tionale mindestens einmal stetig differenzierbar sein. Die Kostenfunktionale
zur Sollgeschwindigkeit, Beschleunigung, Ruck und Drehrate sind in diesem
Fall sogar mehrfach stetig differenzierbar, was die Konvergenz weiter begÃ¼ns-
tigt. Damit auch der Abstand zu einem Polygon-basierten Referenzpfad mehr-
fach differenzierbar ist, muss entweder der Pfad oder die Abstandsfunktion
geeignet interpoliert werden. Erstere kÃ¶nnen bspw. mittels Splines und letz-
tere mittels sog. Pseudodistanzfunktionen [Zie14a] interpoliert werden.


2.4 Fehlertolerante Systeme


Im automatisierten Fahren kÃ¶nnen neben Hardwarefehlern eine Vielzahl von
Softwareproblemen die LeistungsfÃ¤higkeit der Automatisierung und somit
auch die Fahrsicherheit gefÃ¤hrden. Zu den Ursachen zÃ¤hlen u. a. Program-
mierfehler und Laufzeitfehler, wie Konvergenzprobleme einer Trajektori-
enoptimierung. Auch unsichere Trajektorien kÃ¶nnen als Fehler begriffen
werden. Daher ist es unerlÃ¤sslich beim Entwurf der Verhaltensentscheidung
MaÃŸnahmen zur Fehlerdiagnose und -behandlung mit einzubeziehen.


Die Forschung im Bereich der zuverlÃ¤ssigen und fehlertoleranten Systeme
[Ech90, Lap95, Dub13, Mon99, Kor20] entwickelt MaÃŸnahmen zum Entwurf
von Hard- oder Software-Systemen, die trotz potenzieller StÃ¶rungs- und Feh-
lerquellen eine mÃ¶glichst hohe ZuverlÃ¤ssigkeit erreichen. Dabei kÃ¶nnen nach
[Ech90] die Fehlerwahrscheinlichkeit, Ãœberlebenswahrscheinlichkeit, mittle-
re Lebensdauer, Ausfallrate und VerfÃ¼gbarkeit als KenngrÃ¶ÃŸen der ZuverlÃ¤s-
sigkeit dienen.


Die Begriffe StÃ¶rung, Fehler und Ausfall werden umgangssprachlich hÃ¤ufig
synonym verwendet und finden sogar in der Literatur unterschiedliche
teils widersprÃ¼chliche Verwendung. [Dub13, Lap95, Mon99] unterscheiden
zwischen einer StÃ¶rung (engl. â€faultâ€œ), einem Fehler (engl. â€errorâ€œ) und ei-
nem Ausfall (engl. â€failureâ€œ). Eine StÃ¶rung fÃ¼hrt erst bei Aktivierung der
gestÃ¶rten Komponente (z. B. durch einen Funktionsaufruf) zu einem Fehler
(bspw. einem falschen Ergebnis). Wird ein Fehler erkannt, kann dieser ent-
weder behandelt und behoben werden oder im schlimmsten Falle zu einem
Funktions- oder Systemausfall fÃ¼hren. Das deutschsprachige Standardwerk
von Echtle [Ech90] unterscheidet hingegen nicht zwischen StÃ¶rungen und
Fehlern, sondern spricht stattdessen von FehlzustÃ¤nden, die sich auf eine
â€Verletzung der inneren Spezifikationâ€œ beziehen, wÃ¤hrend der Begriff Funk-
tionsausfall die â€Verletzung der Ã¤uÃŸeren Spezifikationâ€œ beschreibt. Auch
[Kor20] definiert den Funktionsausfall als Manifestation eines Fehlzustands,
verwendet fÃ¼r den Fehlzustand allerdings die engl. Begriffe fault und failure
synonym und bezeichnet den Funktionsausfall als error. Auch wenn die
Unterscheidung zwischen einem Fehler und seiner Ursache (der StÃ¶rung)
sinnvoll erscheint und eine Diagnose zu prÃ¤zisieren hilft, ist eine konsistente
Ãœbersetzung aller engl. domÃ¤nenspezifischen Fachbegriffe wie in [Ech90]
vorrangig. Daher werden im weiteren Verlauf dieser Arbeit die Definitionen
nach [Ech90] verwendet.


Die MaÃŸnahmen zur Steigerung der ZuverlÃ¤ssigkeit lassen sich in Fehler-
vermeidung, -beseitigung, -toleranz und -vorhersage kategorisieren [Dub13].
Methoden zur Fehlervermeidung und -beseitigung setzen in der Entwurfs-


und Entwicklungsphase an und setzen u. a. auf QualitÃ¤tskontrolle und Veri-
fikation (vgl. Abschnitt 2.5.1). Der Bereich der Fehlertoleranz beschreibt An-
sÃ¤tze, mit denen FehlzustÃ¤nde im Betrieb festgestellt und FunktionsausfÃ¤lle
verhindert werden kÃ¶nnen. Die Fehlervorhersage beschÃ¤ftigt sich schlieÃŸlich
damit, im laufenden Betrieb die Anzahl fehlerhafter Komponenten zu schÃ¤t-
zen und somit bevorstehende AusfÃ¤lle vorherzusagen.


Neben der Fehlervermeidung ist die Fehlertoleranz eine der wichtigsten SÃ¤u-
len zuverlÃ¤ssiger Systeme und steht daher in der Literatur besonders im Fo-
kus. Zur Fehlertoleranz gehÃ¶rt die Fehlerdiagnose â€“ welche es ermÃ¶glicht ei-
nen vorhandenen Fehlzustand zu erfassen â€“ und die Fehlerbehandlung â€“ die
den Fehlzustand behebt, kompensiert oder ausgrenzt. Abbildung 2.8 stellt die
Methoden zur Fehlerbehandlung dar: FÃ¼r die Fehlerbehebung wird die fehler-
hafte Komponente wieder in einen fehlerfreien Zustand (zurÃ¼ck-)gesetzt (z. B.
Ã¼ber eine Zustandshistorie). Als Fehlerkompensierung bezeichnet man hin-
gegen das Berechnen eines fehlerfreien Ergebnisses, trotz fehlerhafter Kom-
ponente (bspw. Ã¼ber Redundanz und DiversitÃ¤t). Die Fehlerausgrenzung ent-
fernt schlieÃŸlich die fehlerhafte Komponente als letzte drastische MaÃŸnahme
dauerhaft aus dem System (engl. auch â€reconfigurationâ€œ). Abbildung 2.9 fasst
die MaÃŸnahmen, die in zuverlÃ¤ssigen Systemen zum Einsatz kommen, struk-
turiert zusammen.


2.5 Verkehrssicherheit


Der zunÃ¤chst weitgefasste Begriff Verkehrssicherheit beschreibt â€die Abwe-
senheit von unvertretbaren Risiken bei der OrtsverÃ¤nderung von Objekten
(z. B. GÃ¼ter, Personen, Nachrichten) in einem definierten (Verkehrs-)Systemâ€œ
[Dre09]. FÃ¼r den Kontext des automatisierten Fahrens ist dabei die spezifi-
schere Verkehrsmittelsicherheit, also die Abwesenheit von unvertretbaren Ri-
siken und Gefahren bezogen auf die Verkehrsmittel, von Bedeutung. Diese
umfasst sowohl aktive unfallvermeidende MaÃŸnahmen, sowie passive Unfall-
folgen mindernde MaÃŸnahmen.


Dieser Abschnitt 2.5 greift zwei fÃ¼r diese Arbeit relevanten Themenfelder der
aktiven unfallvermeidenden MaÃŸnahmen auf: Die Sicherheitsanalyse in Ab-
schnitt 2.5.1 wird zur Fehlervermeidung beim Systementwurf eingesetzt, wÃ¤h-
rend die Verhaltensverifikation aus Abschnitt 2.5.2 der Fehlererkennung und
-behandlung zur Laufzeit dient.


2.5.1 Sicherheitsanalyse


Das Feld der Sicherheitsanalyse insgesamt, sowie die darunter fallende Zuver-
lÃ¤ssigkeitsanalyse im Besonderen, haben viele in der Automobilbranche eta-
blierte Methoden und Standards hervorgebracht. Die ISO26262 [ISO18] erlÃ¤u-
tert bspw. wie mittels einer GefÃ¤hrdungsanalyse und RisikoabschÃ¤tzung die
funktionale Sicherheit sicherheitsrelevanter elektrischer/elektronischer Sys-
teme im Kraftfahrzeug (KFZ) gewÃ¤hrleistet werden kann (siehe auch [Ros16]).
Die Methoden der sog. â€Safety of the Intended Functionalityâ€œ (SOTIF) erwei-
tern die ISO26262 um die Bereiche Umfeldwahrnehmung, Mensch-Maschine-
Schnittstelle (HMI) und erwartbare Fehlnutzung durch den Anwender. De-
duktive Methoden, wie die Fehlzustandsbaumanalyse (FTA) [DIN07], identi-
fizieren kausale Ketten zwischen Gefahren und deren Ursachen, um die Wahr-
scheinlichkeit festgelegter (i. d. R. kritischer) Ereignisse zu bestimmen. Induk-
tive Methoden, wie die Fehlzustandsart- und -auswirkungsanalyse (FMEA)
[DIN06], werden genutzt, um mÃ¶gliche Produktfehler bereits wÃ¤hrend des
Systementwurfs zu erkennen und ihr Risiko zu bewerten.


Insgesamt sind diese Methoden und Standards allerdings nicht ausreichend,
um die Sicherheit von hoch- oder voll-automatisierten Fahrzeugen zu gewÃ¤hr-
leisten [Way20b]. Daher ist die Sicherheitsanalyse automatisierter Fahrzeuge
noch ein aktives Forschungsfeld [Mer18, Apt19, Sch20, Way20a, Way20b] aus
dem zurzeit viele neue Leitlinien und Normen entstehen [NHT17, SAE21,
SAE20, BSI20a, BSI20b, ISO21]. Eine gute und umfangreiche Zusammen-
fassung Ã¼ber diese Publikationen verschafft [Way20b]. Im Folgenden sollen
die fÃ¼r diese Arbeit wichtigsten Begriffe und Konzepte, in Anlehnung an
[Way20b] und [NHT17], zusammengefasst werden.


Operational Design Domain


Um u. a. einen Szenarienkatalog zur Szenarien-basierten Validierung (siehe
spÃ¤teren Abschnitt zu Systemsicherheit und Validierung) und weitere Sicher-
heitsanforderungen an ein automatisiertes Fahrzeug herzuleiten, wurde das


Konzept der Operational Design Domain (ODD), das in Definition 2.4 erlÃ¤u-
tert wird, eingefÃ¼hrt.


Definition 2.4: Operational Design Domain [SAE21]


Die ODD eines gegebenen Fahrerassistenzsystems oder einer seiner Teilfunktionen
legt die Betriebsbedingungen fest, fÃ¼r welche diese Funktion ausgelegt ist.
Diese schlieÃŸen unter anderem Anforderungen an die Szenerie (z.B. bestimmte er-
forderliche Verkehrs- oder Fahrbahnmerkmale) sowie an die dynamischen Elemente
der Szene (wie Verkehrsdichte oder Anwesenheit von vulnerable Verkehrsteilneh-
mer (VRUs)) und Umweltbedingungen (u.a. Wetter oder GPS-Empfang) ein.


Eine ausfÃ¼hrliche Auflistung und Spezifikation mÃ¶glicher ODD Elemente lie-
fern unter anderem die British Standards Institution [BSI20b] und das Auto-
mated Vehicle Safety Consortiumâ„¢[SAE20]. Im Folgenden soll daraus eine
mÃ¶gliche Kategorisierung zusammengefasst werden.


Die unterstÃ¼tzten Szenerien werden unter anderem beschrieben durch


â€¢ geografisch oder rechtlich festgelegte Zonen wie Stadtbezirke,


â€¢ befahrbare FlÃ¤chen und StraÃŸentypen wie ParkflÃ¤chen oder
Autobahnen,


â€¢ Kreuzungsarten und -infrastruktur wie dreiarmige Knotenpunkte mit
Lichtsignalanlage,


â€¢ besondere Infrastruktur wie Mautschranken oder Tunnel,


â€¢ Fahrbahnelemente wie Leitpfosten und


â€¢ vorÃ¼bergehende StraÃŸenbauten wie Baustellen.


Zur Beschreibung dynamischer Elemente einer ODD zÃ¤hlt


â€¢ die Verkehrsdichte,


â€¢ Art und Zustand anderer Verkehrsteilnehmer und


â€¢ der Zustand des Ego-Fahrzeugs (z. B. seine Geschwindigkeit).


Die Umweltbedingungen, fÃ¼r die die Assistenzfunktion ausgelegt ist, werden
im Wesentlichen definiert durch


â€¢ Wetterbedingungen wie Schneefall oder Regen,


â€¢ Betriebszeiten wie zur Tageszeit oder nachts,


â€¢ die SignalqualitÃ¤t von Satellitennavigationssystemen wie GPS und


â€¢ die VerfÃ¼gbarkeit von Datennetzen wie zum Beispiel V2XÂ¹-Mobilfunk.


Verhaltenskompetenzen


Von der National Highway Traffic Safety Administration (NHTSA) wurden
28 grundlegende Verhaltenskompetenzen, wie sie fÃ¼r die Szenarien-basierte
Validierung verwendet werden kÃ¶nnen, vorgeschlagen und von Waymo auf
insgesamt 47 StÃ¼ck erweitert [Way20a]. Darunter fallen sowohl ganze Fahr-
manÃ¶ver wie die Folgefahrt oder Fahrstreifenwechsel als auch Teilaufgaben,
wie das Einhalten der zugelassenen Maximalgeschwindigkeit oder FÃ¤llen
korrekter Vorfahrtsentscheidungen. HÃ¤ufig sind diese Verhaltenskompeten-
zen an Wahrnehmungsaufgaben gekoppelt und als â€Erkenne und reagiere
angemessenâ€œ-Anweisung formuliert, bspw. â€Erkenne und reagiere auf ein
einscherendes Objektâ€œ. Die detaillierte Auflistung der Verhaltenskompeten-
zen aus [Way20a] kann Anhang A entnommen werden.


Fehlererkennung und Reaktion


Ein automatisiertes System muss sich stets Ã¼berwachen und in der Lage sein,
rechtzeitig Fehlfunktionen und degradierte ZustÃ¤nde in der Hardware oder
den automatisierten Fahrfunktionen [TaÅŸ17], sowie das Verlassen der ODDs
(z. B. durch sich Ã¤ndernde Wetterbedingungen) zu erkennen. Handelt es sich
um eine unkritische StÃ¶rung, kann das Fahrzeug ggf. in einem degradierten
Modus, also bspw. bei reduzierter Geschwindigkeit, die Fahrt fortsetzen. Bei
schwerwiegenderen Fehlern muss das System in einen risikominimalen Zu-
stand (MRC), wie in Definition 2.5 aus dem â€Gesetz zum autonomen Fah-
renâ€œ [Bun21] festgelegt, Ã¼berfÃ¼hrt werden. Je nach Schwere des Fehlers wird
hierfÃ¼r entweder in der Hardware- oder Verhaltens-Ebene eine angemessene


FOOTNOTE:Â¹ V2X umfasst Fahrzeug-Fahrzeug-Kommunikation (V2V), Fahrzeug-Infrastruktur-Kommunika-
tion (V2I) und Kommunikation zur Flottenverwaltung (V2F).


Reaktion bewirkt. Bei weniger schwerwiegenden FunktionsstÃ¶rungen kann
die Verhaltens-Ebene ein sog. risikominimierendes ManÃ¶ver durchfÃ¼hren, das
das Fahrzeug bspw. auf einem Standstreifen zum Stillstand bringt. Bei einem
schwerwiegenden Systemausfall, der auch die Verhaltens-Ebene betrifft, be-
tÃ¤tigt die Hardware-Ebene eine Notbremsung.


Definition 2.5: Risikominimaler Zustand [Bun21]


Ein risikominimaler Zustand (MRC) ist ein Zustand, in den sich das Kraftfahrzeug
mit autonomer Fahrfunktion auf eigene Veranlassung oder auf Veranlassung der
technischen Aufsicht selbstÃ¤ndig versetzt, um unter angemessener Beachtung der
Verkehrssituation die grÃ¶ÃŸtmÃ¶gliche Verkehrssicherheit fÃ¼r andere Verkehrsteilneh-
mende und Dritte zu gewÃ¤hrleisten.


Definition 2.6: Risikominimierendes ManÃ¶ver [Apt19]


Ein risikominimierendes ManÃ¶ver (MRM) ist ein ManÃ¶ver, das das Fahrzeug in einen
MRC Ã¼berfÃ¼hrt.


In [Apt19], einer gemeinsamen Publikation zahlreicher Automobilhersteller
und -zulieferer, darunter Audi, BMW, Daimler, VW, Intel und Here, werden
mÃ¶gliche MRCs und MRMs vorgestellt:


Beispiel 2.2: Risikominimale ZustÃ¤nde aus [Apt19]


Je nach Fehlerschwere und ob ein FahrzeugfÃ¼hrer anwesend ist, kommen verschie-
dene MRCs infrage.


Ãœbernahme durch FahrzeugfÃ¼hrer Der FahrzeugfÃ¼hrer hat die Fahraufgabe vollstÃ¤n-
dig Ã¼bernommen.


EingeschrÃ¤nkter Betrieb Fahrzeug ist noch innerhalb der eingeschrÃ¤nkten Fahrfunk-
tionen betriebsbereit. Je nach Funktionsdefinition und verbleibenden FÃ¤hig-
keiten kann es mehrere eingeschrÃ¤nkte BetriebszustÃ¤nde geben.


Betrieb einstellen Diese Bedingung beschreibt einen Fahrzeugzustand, der eine si-
chere Abschaltung der Funktion ermÃ¶glicht.


