Karlsruher Schriften
zur Anthropomatik


Band 60


Patrick Philipp


Ãœber die Formalisierung und Analyse
medizinischer Prozesse im Kontext von
Expertenwissen und kÃ¼nstlicher Intelligenz


Patrick Philipp


Ãœber die Formalisierung und Analyse
medizinischer Prozesse im Kontext von
Expertenwissen und kÃ¼nstlicher Intelligenz


Karlsruher Schriften zur Anthropomatik
Band 60
Herausgeber: Prof. Dr.-Ing. habil. JÃ¼rgen Beyerer


Eine Ãœbersicht aller bisher in dieser Schriftenreihe
erschienenen BÃ¤nde finden Sie am Ende des Buchs.


Ãœber die Formalisierung und
Analyse medizinischer Prozesse
im Kontext von Expertenwissen
und kÃ¼nstlicher Intelligenz


von
Patrick Philipp


Karlsruher Institut fÃ¼r Technologie
Institut fÃ¼r Anthropomatik und Robotik


Ãœber die Formalisierung und Analyse medizinischer Prozesse
im Kontext von Expertenwissen und kÃ¼nstlicher Intelligenz


Zur Erlangung des akademischen Grades eines Doktors der Ingenieur-
wissenschaften von der KIT-FakultÃ¤t fÃ¼r Informatik des Karlsruher
Instituts fÃ¼r Technologie (KIT) genehmigte Dissertation


von Patrick Philipp


Tag der mÃ¼ndlichen PrÃ¼fung: 16. Februar 2023
Erster Gutachter: Prof. Dr.-Ing. habil. JÃ¼rgen Beyerer
Zweiter Gutachter: Prof. Dr. Michael Beigl


Impressum


Karlsruher Institut fÃ¼r Technologie (KIT)
KIT Scientific Publishing
StraÃŸe am Forum 2
D-76131 Karlsruhe


KIT Scientific Publishing is a registered trademark
of Karlsruhe Institute of Technology.
Reprint using the book cover is not allowed.


www.ksp.kit.edu


This document â€“ excluding parts marked otherwise, the cover, pictures and graphs â€“
is licensed under a Creative Commons Attribution 4.0 International License (CC BY 4.0):
https://creativecommons.org/licenses/by/4.0/deed.en


The cover page is licensed under a Creative Commons
Attribution-No Derivatives 4.0 International License (CC BY-ND 4.0):
https://creativecommons.org/licenses/by-nd/4.0/deed.en


Print on Demand 2023 â€“ Gedruckt auf FSC-zertifiziertem Papier


ISSN 1863-6489


ISBN 978-3-7315-1289-9


DOI 10.5445/KSP/1000156884


Kurzfassung


Die Digitalisierung hat bereits viele Bereiche der Wirtschaft und des gesell-
schaftlichen Lebens verÃ¤ndert. Auch unterliegen die Aspekte des Gesund-
heitswesens und der klinischen Praxis einem digitalen Wandel. Dabei steigt
gleichzeitig der Bedarf an weltweit akzeptierbaren LÃ¶sungen zum Austausch
und zur Auswertung medizinischer Daten. In diesem Zuge gewinnen die Fast
Healthcare Interoperability Resources (FHIR) zunehmend an Bedeutung â€“ in
Deutschland werden sie beispielsweise in Zusammenhang mit der Elektroni-
schen Patientenakte (ePA) eingesetzt.


Im Hinblick auf diese Entwicklungen, wird FHIR in der vorliegenden Disser-
tation zur WissensreprÃ¤sentation genutzt. Dabei wird in einem ersten Bei-
trag die probabilistische Erweiterung eines FHIR DataRequirements vollzo-
gen. Die Erweiterung erlaubt es, Observationswahrscheinlichkeiten zu hin-
terlegen und so ein LÃ¼cke bei der bisherigen Prozessmodellierung in FHIR zu
schlieÃŸen.


DarÃ¼ber hinaus wird in dieser Arbeit eine strukturierte Vorgehensweise zur
Wissensakquisition und -formalisierung von medizinischen Prozessen im Be-
reich der Diagnostik sowie der Therapie vorgestellt. Das Konzept beschreibt
ein Expertensystem, bei welchem FHIR als Wissensbasis eingesetzt wird. FÃ¼r
den Wissenserwerb dienen Ablaufmodelle, die fÃ¼r alle Seiten, sprich: sowohl
fÃ¼r den medizinischen als auch fÃ¼r den technischen DomÃ¤nenexperten, ver-
stÃ¤ndlich sind. Dies ist eine wichtige Voraussetzung, um in der tatsÃ¤chlichen
Praxis gemeinsam das Prozesswissen formalisieren zu kÃ¶nnen.


GrundsÃ¤tzlich kÃ¶nnen verschiedene Ablaufmodelle zur Formalisierung her-
angezogen werden. In dieser Arbeit werden, aufgrund diverser positiver Ei-
genschaften, UML AktivitÃ¤tsdiagramme exemplarisch eingesetzt.


FÃ¼r das dargestellte Konzept kÃ¶nnen aber auch andere Modelle, wie z.B. Er-
eignisgesteuerte Prozessketten (EPK), genutzt werden. ErmÃ¶glicht wird dies
durch insgesamt drei Transformationsschritte. Sie entkoppeln die Ablaufmo-
delle von der eigentlichen Wissensbasis. Dabei werden mittels zweier (bereits
existierender) Transformationen die Ablaufmodelle zunÃ¤chst in Workflow-
Netze und spÃ¤ter in ProzessbÃ¤ume Ã¼berfÃ¼hrt. Die anschlieÃŸende ÃœberfÃ¼h-
rung eines Prozessbaums in einen FHIR-Plan ist Beitrag dieser Arbeit. Hierin
wird gezeigt, dass die dargelegte Transformation sowohl fÃ¼r Hin- als auch fÃ¼r
RÃ¼ckrichtung strukturerhaltend ist.


Darauf aufbauend wird eine neu entwickelte Transformation eines FHIR-
Plans in ein expertenbasiertes Dynamisches Bayes-Netz (DBN) zur Phasen-
erkennung besprochen. Das Ergebnis wird anhand zweier prototypischer
Vertreter chirurgischer Interventionen beleuchtet: die endoprothetische Ver-
sorgung eines Patienten mittels einer totalen Endoprothese der HÃ¼fte sowie
die laparoskopische Entfernung der Gallenblase. In einer Vor- und Realstu-
die sowie an einem Ã¶ffentlichen Datensatz werden die Modelle schlieÃŸlich
einer Leistungsbewertung unterzogen. Zum Einsatz kommt hierfÃ¼r eine ver-
schachtelte Kreuzvalidierung. Unter BerÃ¼cksichtigung der gewÃ¤hlten Werte
(Precision, Recall, Jaccard-Score) zeigt sich die Ãœberlegenheit des Ansatzes
bezÃ¼glich der Vergleichsmodelle.


Danksagung


Die vorliegende Dissertation entstand im Rahmen meiner TÃ¤tigkeit als wis-
senschaftlicher Mitarbeiter sowohl am Lehrstuhl fÃ¼r Interaktive Echtzeitsys-
teme (IES) des Karlsruher Instituts fÃ¼r Technologie (KIT), als auch in der Ab-
teilung Interaktive Analyse und Diagnose (IAD) des Fraunhofer-Instituts fÃ¼r
Optronik, Systemtechnik und Bildauswertung (IOSB).


An dieser Stelle mÃ¶chte ich mich bei allen bedanken, die mich wÃ¤hrend meiner
Promotion begleitet und unterstÃ¼tzt haben.


Insbesondere danke ich den Personen, die mir diese Arbeit ermÃ¶glicht ha-
ben: Meinem Doktorvater und Institutsleiter des Fraunhofer IOSB Professor
Dr.-Ing. habil. JÃ¼rgen Beyerer fÃ¼r die FÃ¶rderung meiner Arbeiten, die inten-
siven Diskussionen in Freitagsrunden und Sommerseminar sowie das stets
entgegengebrachte Vertrauen. Ebenso danke ich Herrn Professor Dr. Michael
Beigl fÃ¼r die Ãœbernahme des Koreferats und dem Interesse an meiner Arbeit.


DarÃ¼ber hinaus gebÃ¼hrt mein Dank den Kolleginnen und Kollegen des Lehr-
stuhls, der Abteilung IAD und insbesondere den Mitarbeitenden meiner For-
schungsgruppe Decision Support Systems am Fraunhofer IOSB.


Meiner Frau Lena gilt ein spezieller Dank fÃ¼r ihr entgegengebrachtes Ver-
stÃ¤ndnis und genial-denkwÃ¼rdige Diskussionen.


1 Einleitung


KÃ¼nstliche Intelligenz (KI) wird viele Aspekte der klinischen Praxis und des
Gesundheitswesens entscheidend mitprÃ¤gen. Dies betrifft nach [Yu18] u.a.:


â€¢ die UnterstÃ¼tzung bei der Diagnosestellung,


â€¢ die Assistenz bei chirurgischen Interventionen,


â€¢ die Auswertung der Ergebnisse bildgebender Verfahren,


â€¢ die UnterstÃ¼tzung in der Arzneimittelforschung.


Die BeitrÃ¤ge der vorliegenden Dissertation zur Formalisierung und Analyse
von medizinischen Prozessen lassen sich in den beiden erstgenannten Berei-
chen verorten (vgl. Abbildung 1.1). Sprich: der Bestimmung der zugrunde-
liegenden Erkrankung eines Patienten und der Assistenz bei chirurgischen
BehandlungsmaÃŸnahmen.


Als Grundlage fÃ¼r KÃ¼nstliche Intelligenz (KI)-Methoden stehen klassischer-
weise groÃŸe Datenmengen im Fokus. Im Bereich der bildgebenden Verfahren
kÃ¶nnen beispielsweise anhand groÃŸer Lern-, Validierungs- und Teststichpro-
ben Tumore in Bildschichten segmentiert oder Anomalien erkannt werden.


In anderen Bereichen stehen geeignete Daten nur eingeschrÃ¤nkt oder un-
strukturiert zur VerfÃ¼gung. Zum Beispiel liegen bei Diagnosestellung hÃ¤ufig
groÃŸe Teile der Daten in Form von Freitexten vor und sind damit fÃ¼r daten-
basierte KI-Methoden nicht oder nur unzureichend nutzbar. Um die Daten-
schÃ¤tze mittels Methoden der KI zu bergen, wird deswegen Ã¼blicherweise ei-
ne Strukturierung der Daten angestrebt. In der Vergangenheit entstand so ein
ganzer StrauÃŸ an verschiedenen InsellÃ¶sungen zur Strukturierung und Spei-
cherung. Gleichzeitig erschweren InsellÃ¶sungen aber Daten auf weltweiter


Abbildung 1.1: Wichtige Aspekte auf dem Gebiet des Gesundheitswesens und der klinischen
Praxis, in denen kÃ¼nstliche Intelligenz nach [Yu18] einen prÃ¤genden Einfluss
haben wird. Die BeitrÃ¤ge der vorliegenden Dissertation liegen in den markierten
Bereichen d.h. bei der UnterstÃ¼tzung der Diagnosestellung sowie der Assistenz
bei chirurgischen Interventionen (vgl. Marker A).


Ebene zu sammeln, auszutauschen und fÃ¼r nachfolgende Auswertungen zu
nutzen. Abseits von InsellÃ¶sungen entstand somit der Bedarf an weltweit ak-
zeptierbaren LÃ¶sungen und InteroperabilitÃ¤t.


In diesem Zuge gewannen die sogenannten Fast Healthcare Interoperability
Resources (FHIR) in den letzten Jahren zunehmend an Bedeutung [Leh19a,
Hub20]. Schon im Jahr 2018 verstÃ¤ndigten sich die Technologieunternehmen
IBM, Microsoft, Oracle, Google, Amazon und Salesforce in einer gemeinsamen
ErklÃ¤rung auf die Notwendigkeit, bestehende Hemmnisse bei der medizini-
schen DatenreprÃ¤sentation zu beseitigen. In dieser ErklÃ¤rung werden FHIR
und angeschlossene Projekte bereits explizit genannt [Inf18, Leh19a], denn
sie sollen es ermÃ¶glichen, medizinische Daten mit Methoden der KI weltweit,
sowie unternehmensÃ¼bergreifend effektiv und effizient nutzbar zu machen
[Leh19b].


Weiterhin ergab sich speziell in Deutschland die Frage nach akzeptierbaren
SoftwarelÃ¶sungen im Hinblick auf die Elektronische Patientenakte (ePA), de-
ren Entwicklung durch entsprechende Gesetze in den Jahren zuvor angeregt
wurden. Im Jahr 2019 stellten hierzu [Plo19] ein Konzept vor, welches FHIR


nutzt, um durch eine mÃ¶glichst vertrauenswÃ¼rdige LÃ¶sung eine hohe Akzep-
tanz bei den Benutzern zu erreichen. Heute, im Jahr 2022, basieren Schnitt-
stellen, sowie die auf der ePA ablegbaren und in Bearbeitung befindlichen
medizinischen Informationsobjekte (MIO), wie beispielsweise Impfpass, Mut-
terpass oder das ZahnÃ¤rztliche Bonusheft, auf FHIR [Kas21].


Abgeleitet aus den genannten Entwicklungen, nutzt die vorliegende Disserta-
tion FHIR als Vehikel zur WissensreprÃ¤sentation im Rahmen der Prozessmo-
dellierungen und erweitert dieses wo notwendig.


Besonders in Bereichen, die datenarm aber wissensreich sind, kann darÃ¼ber
hinaus das verfÃ¼gbare Expertenwissen eine entscheidende Rolle spielen. Dies
gilt beispielsweise fÃ¼r medizinische Prozesse im Rahmen der Diagnosestel-
lung oder der chirurgischen Interventionen, die interessanterweise hÃ¤ufig
noch unzureichend unter den oben genannten Gesichtspunkten betrachtet
werden. Wichtig werden solcherlei Ãœberlegungen vor allem dann, wenn
am Ende eine praxistaugliche Assistenz im Rahmen medizinischer Prozesse
konzipiert und bereitgestellt werden soll. Aus diesem Grunde beschÃ¤ftigen
sich die BeitrÃ¤ge der vorliegenden Arbeit auch mit diesem Aspekt.


1.1 Eigene BeitrÃ¤ge


Einer der BeitrÃ¤ge dieser Dissertation ist eine strukturierte Vorgehensweise
zur Wissensakquisition und -formalisierung von medizinischen Prozessen fÃ¼r
eine KI-basierte EntscheidungsunterstÃ¼tzung im Bereich der medizinischen
Diagnostik und Therapie, vgl. hierzu Abbildung 1.2.


Medizinische Prozesse werden dabei durch Prozessmodelle beschrieben. Hier-
zu muss das vorhandene Expertenwissen im Dialog mit dem Experten for-
malisiert werden. Ziel der Formalisierung ist letztlich ein fÃ¼r alle Seiten ver-
stÃ¤ndliches Ablaufmodell, welches den Ablauf der einzelnen Prozessschritte
des medizinischen Prozesses beschreibt. GrundsÃ¤tzlich kÃ¶nnen fÃ¼r ein sol-
ches Ablaufmodell unterschiedliche Prozessmodelle herangezogen werden.
Aufgrund ihrer VerstÃ¤ndlichkeit auch fÃ¼r nicht-technische Nutzer eignen sich


Abbildung 1.2: Die Formalisierung des menschlichen Wissens kann im Dialog der medizini-
schen und technischen DomÃ¤nenexperten vollzogen werden. Ergebnis ist ein
fÃ¼r alle Seiten verstÃ¤ndliches Ablaufmodell, welches Ã¼ber Zwischenmodelle in
die FHIR-basierte Wissensbasis gelangt. ZusÃ¤tzlich kÃ¶nnen Methoden zur Ent-
deckung von AblÃ¤ufen (vgl. Process Mining) eingebunden werden. Aus der Wis-
sensbasis kÃ¶nnen wiederum Abgleichmodelle fÃ¼r die Bereitstellung von Assis-
tenzfunktionen erzeugt werden.


insbesondere grafische Prozessmodelle, wie beispielsweise GeschÃ¤ftsprozess-
modell und -notation (BPMN), Ereignisgesteuerte Prozessketten (EPK) oder
UML AktivitÃ¤tsdiagramme [Ko09]. In dieser Arbeit werden UML AktivitÃ¤ts-
diagramme zur Modellierung und den Wissenserwerb genutzt. Die BeitrÃ¤ge
der Arbeit sind allerdings von den eben genannten, konkreten Prozessmodel-
len Ã¼ber Zwischenmodelle entkoppelt, sodass diese mit alternativen Modellen
zusammenspielen kÃ¶nnen. Weiterhin bieten die Zwischenmodelle eine Naht-
stelle zu unterschiedlichen Techniken fÃ¼r das datenbasierte Entdecken von
Prozessen.


Die in den Prozessmodellen enthaltene Information muss schlieÃŸlich fÃ¼r eine
Wissensbasis verfÃ¼gbar gemacht werden. DafÃ¼r werden die im Expertendia-
log erstellten UML AktivitÃ¤tsdiagramme in FHIR Ã¼berfÃ¼hrt, sodass die AblÃ¤u-
fe schlieÃŸlich als FHIR-PlÃ¤ne hinterlegt werden kÃ¶nnen. Dies erfolgt durch


drei Transformationen, von denen zwei bereits Stand der Technik sind. Die
dritte Transformation stellt einen eigenen Beitrag dar â€“ hierin werden Pro-
zessbÃ¤ume und FHIR-PlÃ¤ne hin- und rÃ¼cktransformiert.


In einem weiteren Beitrag wird eine probabilistische Erweiterung einer FHIR
Ressource vorgestellt und schlieÃŸlich wird in einem finalen Beitrag ein pro-
babilistisches Abgleichmodell fÃ¼r die Assistenz im Rahmen chirurgischer In-
terventionen abgeleitet. Das Abgleichmodell wird dann anhand zweier proto-
typischer Vertreter evaluiert.


1.2 Gliederung


Die vorliegende Arbeit enthÃ¤lt sechs Kapitel, deren Inhalt nachstehend skiz-
ziert wird:


Kapitel 2 beleuchtet die Grundlagen der wissensbasierten Modellierung.
Hierbei wird zunÃ¤chst auf Expertensysteme und deren Zusammen-
hang mit KÃ¼nstlicher Intelligenz eingegangen. Weiterhin werden
Bayes-Netze als ProblemlÃ¶sungskomponente ausfÃ¼hrlich erlÃ¤utert
und schlieÃŸlich die sogenannten Fast Healthcare Interoperability
Resources zur WissensreprÃ¤sentation dargestellt sowie erweitert.


Kapitel 3 widmet sich den Begrifflichkeiten der Prozessmodellierung und
stellt Notationselemente sowie Verschaltungen von Petri-Netzen,
UML AktivitÃ¤tsdiagrammen als auch ProzessbÃ¤umen vor.


Kapitel 4 stellt die entwickelte Transformation zwischen ProzessbÃ¤umen und
FHIR dar. ZusÃ¤tzlich wird die Strukturerhaltung bei Hin- und RÃ¼ck-
transformation beleuchtet.


Kapitel 5 beschreibt die medizinischen HintergrÃ¼nde zweier prototypischer
chirurgischer Intervention: Zum einen die laparoskopische Chole-
zystektomie und zum anderen die totale Endoprothese der HÃ¼fte.
Darauf aufbauen wird auf die Konstituenten des zugrunde liegen-
den Problems und die Bewertung der ProblemlÃ¶sung eingegangen.


SchlieÃŸlich wird ausgehend vom Stande der Technik der eigene Bei-
trag umrissen und schlieÃŸlich detailliert vorgestellt.


Kapitel 6 fasst die Erkenntnisse zusammen und gibt einen Ausblick.


Diese Arbeit enthÃ¤lt neben den beschriebenen Kapiteln einen medizinischen
Glossar (ab Seite 207), ein Symbolverzeichnis (ab Seite 209), ein Literaturver-
zeichnis (ab Seite 215), ein Verzeichnis der eigenen Publikationen (ab Seite
237) und ein Verzeichnis betreuter studentischer Arbeiten (ab Seite 245).


2 Wissensbasierte Modellierung


Wissensbasierte Modellierung steht in engem Zusammenhang mit dem For-
schungsgegenstand der Wissensbasierte Systeme (WBS), die in Kapitel 2.1
vorgestellt werden. Speziell auf den Aufbau von Expertensystemen wird im
anschlieÃŸenden Kapitel 2.2 eingegangen. WBS und Expertensysteme haben
sich als Teilgebiet der KI entwickelt â€“ ein Ãœberblick und eine Einordnung wird
in Kapitel 2.3 vorgenommen. Auf Wahrscheinlichkeitsbegriffe und -theorie
wird in Kapitel 2.4 gemeinsam mit Bayes-Netze als ProblemlÃ¶sungskompo-
nente eingangen. SchlieÃŸlich werden als Grundlage zur WissensreprÃ¤sentati-
on die sogenannten Fast Healthcare Interoperability Resources (FHIR) in Ka-
pitel 2.5 vorgestellt.


2.1 Wissensbasierte Systeme


Ãœber die Zeit hinweg finden sich verschiedene Definitionen des Begriffs
WBS [Ort77, Kur92, Ake09, Pup13b]. Allen gemein ist die Aufspaltung der
FOOTNOTE:Architektur des Systems in zwei Bereiche (vgl. Abbildung 2.1). Auf der einen
Seite steht die sogenannte Wissensbasis mit spezifischem Wissen Ã¼ber den
Anwendungsbereich. Dem gegenÃ¼ber steht die tatsÃ¤chliche Verarbeitung des
Wissens (Wissensverarbeitung) in Form einer anwendungsunabhÃ¤ngigen
ProblemlÃ¶sungskomponente.


An Anlehnung an die Definitionen aus [Ort77, Kur92, Ake09, Pup13b], wird
in der vorliegenden Arbeit ein WBS definiert als:


Definition 2.1. Ein WBS ist ein System oder Programm, bei dem das Wis-
sen Ã¼ber ein Anwendungsgebiet (Wissensbasis) getrennt ist von allgemeinen
ProblemlÃ¶sungsmethoden (Wissensverarbeitung).


Diese Trennung hat zwei Vorteile: Zum einen kÃ¶nnen allgemeine Methoden
zur Wissensverarbeitung herangezogen werden, die unabhÃ¤ngig von der Wis-
sensbasis eines konkreten Anwendungsfalles sind und die auch auf weitere
Anwendungen Ã¼bertragbar sind. Zum anderen kann die Wissensbasis aktua-
lisiert und erweitert werden, ohne dass dabei die Algorithmen der Wissens-
verarbeitung angepasst werden mÃ¼ssen [Kol09].


Abbildung 2.1: AuchwennesverschiedenartigeDefinitionendesBegriffsWBSgibt,istdieTren-
nung zwischen Fachwissen Ã¼ber das Anwendungsgebiet des WBS und der ei-
gentlichen Wissensverarbeitung mittels allgemeiner ProblemlÃ¶sungsmethoden
allen Definitionen gemein.


2.2 Expertensysteme


In der Literatur findet sich Ã¼blicherweise eine Abgrenzung des Begriffs des
Expertensystems zum Begriff WBS. Hierbei existieren verschiedene Sicht-
weisen, von einigen Autoren werden die Begriffe auch synonym verwendet
[Hop92]. Eine gÃ¤ngige MÃ¶glichkeit ein Expertensystem von einem WBS ab-
zugrenzen ist die Herkunft des im System reprÃ¤sentierten Wissens. Dabei sind
Expertensysteme spezielle WBS, deren Wissen von Experten stammt [Wat86].


Sie kÃ¶nnen somit als Teilmenge der WBS angesehen werden. Bei dieser Defi-
nition bleibt es Auslegungssache, ob die Wissensbasis eines Expertensystems
ausschlieÃŸlich aus Expertenwissen bestehen muss. Denkbar ist auch eine da-
tengetriebene Erweiterung der Wissensbasis durch Methoden des maschinel-
len Lernens.


In der vorliegenden Arbeit wird fÃ¼r Expertensysteme eine Ã¤hnliche Definition
nach Puppe herangezogen [Pup13b]:


Definition 2.2. Ein Expertensystem ist ein WBS, mit dem die Schlussfolge-
rungsfÃ¤higkeit und das bereichsspezifische Wissen von Experten nachgebil-
det werden soll.


Diese Definition umfasst damit zwei Aspekte:


1. Expertensysteme sind Teilmenge der WBS.


2. Der Begriff Expertensystem entstammt einer externen Sichtweise und
beschreibt, wie die Umwelt das System wahrnimmt. Speziell bleibt da-
bei frei, wie das nachzubildende bereichsspezifische Wissen erworben
wird. Denkbar sind verschiedene Wissensquellen (beispielsweise Da-
tenbanken, BÃ¼cher, Leitlinien oder menschliche Experten [Bei19]), so-
wie die (teilweise) Generierung der Wissensbasis mit dem Werkzeug
des Maschinellen Lernens (beispielsweise Erlernen von Entscheidungs-
bÃ¤umen zur Entwicklung der Wissensbasis [Bei19]) .


Die Architektur eines Expertensystems besteht aus einzelnen Komponenten,
die in einem Austausch miteinander stehen. Grundlegend sind aber nur die
Wissensbasis und die ProblemlÃ¶sungskomponente.


Die Wissensbasis bildet dabei den Kern eines Expertensystems â€“ in ihr wird
das benÃ¶tigte Fachwissen Ã¼ber das Anwendungsgebiet des Expertensystems
in einer geeigneten ReprÃ¤sentationsform abgelegt [Kur92]. UnabhÃ¤ngig von
der Art der WissensreprÃ¤sentation kann der Inhalt einer Wissensbasis nach


[Pup13a] weiter unterteilt werden in sogenanntes fallspezifisches Wissen und
bereichsbezogenes ExpertenwissenÂ¹.


Dabei bezieht sich das fallspezifische Wissen ausschlieÃŸlich auf eine konkrete,
gerade betrachtete Problemstellung im Anwendungsgebiet des Expertensys-
tems. Fallspezifisches Wissen kann aufgrund von Beobachtungen â€“ im me-
dizinischen Bereich beispielsweise aufgrund von Untersuchungsergebnissen
eines Patienten â€“ vorliegen. Das fallspezifische Wissen kann vom Benutzer
des Expertensystems wÃ¤hrend der Nutzung eingegeben [Kna93] oder ohne
direkte Benutzerbeteiligung erhoben werden [Bie13].


Das bereichsbezogene Expertenwissen bezieht sich im Gegensatz zum fall-
spezifischen Wissen auf Wissen, das Ã¼ber einen einzelnen konkreten Fall aus
dem Anwendungsgebiet des Expertensystems hinaus geht â€“ es meint damit
Wissen, das alle FÃ¤lle aus dem Anwendungsgebiet umfasst. Es kann sich da-
bei um Fachwissen der DomÃ¤nenexperten handeln â€“ wie beispielsweise das
Wissen Ã¼ber den Ablauf einer Operation.


Am Anfang der Entwicklung eines Expertensystems steht die Akquisition des
Fachwissens aus der AnwendungsdomÃ¤ne. Zur Akquisition des Wissens dient
im Expertensystem eine sogenannte WissenserwerbskomponenteÂ², die den
Aufbau der Wissensbasis unterstÃ¼tzt [Bei19, Pup13b].


Da unterschiedliche Quellen fÃ¼r den Wissenserwerb in Frage kommen
[Bei19], z.B. Leitlinien oder menschliche Experten, muss das Expertenwissen
aus diesen Quellen im Schritt der Wissensakquisition geeignet erhoben und
in einem Wissensmodell dargestellt werden kÃ¶nnen [Kur92].


Eine nicht zu unterschÃ¤tzende Herausforderung ist dabei die Akquisition von
Wissen mittels Expertendialog [Alt13]: Da das domÃ¤nenspezifische Wissen
eines Experten hÃ¤ufig nicht bewusst vorhanden ist, sondern unbewusst ange-
wandt wird, gestaltet sich dessen Ermittlung und Strukturierung in der Praxis


FOOTNOTE:Â¹ Hinweis: Beierle unterteilt Ã¤hnlich in fallspezifisches Wissen und regelhaftes Wissen [Bei19].
Wobei letzteres im Sinne eines allgemeinen bzw. bereichsbezogenen Wissens zu interpretieren
ist und nicht im Sinne der Form der ReprÃ¤sentation in Form von Regeln.


FOOTNOTE:Â² Hinweis: Einige Autoren sprechen hier auch von der Wissensakquisitionskomponente (vgl.
[Kur92, Alt13]).


hÃ¤ufig schwierig. Gleichzeitig kann das Ergebnis der Wissensakquisition aber
maÃŸgeblich fÃ¼r den Erfolg des Expertensystems verantwortlich sein. Der Pro-
zess des Wissenserwerbs sollte daher sorgfÃ¤ltig vorbereitet und durchgefÃ¼hrt
werden [Alt13].


Deswegen ist einer der BeitrÃ¤ge dieser Arbeit eine strukturierte Vorgehens-
weise fÃ¼r die Wissensakquisition und -formalisierung fÃ¼r Expertensysteme
im Bereich der medizinischen Diagnostik und Therapie.


2.3 KÃ¼nstliche Intelligenz


Als Ursprung des Forschungsfeldes KI wird Ã¼blicherweise eine Arbeitstagung
zur Maschinenintelligenz angesehen, die im Jahre 1956 von John McCarthy
am Dartmouth College in New Hampshire organisiert wurde [McC04, Rus09].
Dabei erklÃ¤rte McCarthy sinngemÃ¤ÃŸ: â€Ziel der KI ist es, Maschinen zu entwi-
ckeln, die sich verhalten, als verfÃ¼gten sie Ã¼ber Intelligenzâ€œÂ¹.


Als eine MÃ¶glichkeit eine solche Maschinenintelligenz zu messen, galt zu-
nÃ¤chst der Turing Test. Dabei tritt ein menschlicher Fragesteller mit zwei
verschiedenen GesprÃ¤chspartnern in Kontakt, zu denen er weder Sicht- noch
HÃ¶rkontakt hat.


Ãœber eine Tastatur und einen Bildschirm kann er mit den GesprÃ¤chspartnern
kommunizieren. Kann der Fragesteller auch nach intensiver Befragung nicht
sagen, welcher der beiden GesprÃ¤chspartner die Maschine ist, so hat die Ma-
schine den Turing Test bestanden. Der Maschine wird dann ein dem Men-
schen ebenbÃ¼rtiges DenkvermÃ¶gen unterstellt [Tur50]Â².


FOOTNOTE:Â¹ Hinweis: Schon zuvor hatte Alan Turing die zentrale Frage â€KÃ¶nnen Maschinen denken?â€œ for-
muliert [Tur09]. Eine Frage die Hermann Schmidt sowie Norbert Wiener (vgl. das Wiener Filter
bzw. Wiener-Kolmogoroff-Filter) mit dem Begriff â€Kybernetikâ€œ verknÃ¼pften [Wie48]. Nachhal-
tig in den 1960er Jahren geprÃ¤gt von Karl Steinbuch [Ste65], ist die Kybernetik heute weitest-
gehend im Begriff der KI aufgegangen.


FOOTNOTE:Â² Hinweis: Die Testergebnisse hÃ¤ngen also nicht von der FÃ¤higkeit der Maschine ab, â€korrekteâ€œ
Antworten im Hinblick auf die Konstituenten des Problems zu geben, sondern nur davon, wie
sehr ihre Antworten denen eines Menschen (bzw. der Menschen der Stichprobe) Ã¤hneln.


Jedoch wurde, insbesondere von dem Philosophen John Searle, Kritik am Tu-
ring Test hervorgebracht: er prÃ¼fe nur auf FunktionalitÃ¤t und nicht auf Ver-
stÃ¤ndnis. Um dies darzustellen, zog Searle das Gedankenexperiment des â€Chi-
nesischen Zimmersâ€œ heran, vgl. [Sea80]. Dieses Gedankenexperiment beginnt
zunÃ¤chst mit der Hypothese, dass es gelungen ist eine Maschine zu bauen, die
sich so verhÃ¤lt, als verstÃ¼nde sie Chinesisch, d.h. die Maschine kann basierend
auf einem chinesischen Eingabetext einen passenden Ausgabetext so bereit-
stellen, dass sie im Turing Test einen chinesischen Muttersprachler Ã¼berzeu-
gen kann.


Laut Searle stellt sich nun die Frage, ob eine solche Maschine tatsÃ¤chlich Chi-
nesisch versteht, oder ob sie das VerstÃ¤ndnis des Chinesischen nur simuliert.
Um diesen Unterschied zu verdeutlichen, beschreibt Searle eine angepasste
Version des Turing Tests: Auch in seinem Experiment kommuniziert ein Fra-
gesteller ohne Sicht- und HÃ¶rkontakt mit einem GesprÃ¤chspartner, der sich in
einem anderen Zimmer befindet. In diesem Fall ist der Fragesteller jedoch chi-
nesischer Muttersprachler und stellt seine Fragen demnach in chinesischen
Schriftzeichen. Sein GegenÃ¼ber, in diesem Fall ein Mensch, ist des Chinesi-
schen nicht mÃ¤chtig. Hat er im Zimmer aber Zugriff auf eine Schriftsammlung
in chinesischen Zeichen, die viele verschiedene Fragen und dazu passende
Antworten enthÃ¤lt, kann er die Sequenzen an Schriftzeichen in den Fragen
des Fragestellers auf der Ebene der Zeichenerkennung mit den Fragen in der
Schriftsammlung vergleichen und so die passenden Antwortzeichen heraus-
finden. Hierbei muss er weder Frage noch Antwort verstehen, kann aber sei-
nem GegenÃ¼ber vorgaukeln, er verstÃ¼nde Chinesisch.


Kann also analog eine Maschine auf in chinesischer Schrift gestellte Fragen
mit passenden chinesischen Schriftzeichen antworten, sodass sie den Turing
Test besteht, kann hierdurch noch nicht angenommen werden, dass die Ma-
schine tatsÃ¤chlich versteht was sie Ã¼bersetzt â€“ also eine Art von Bewusstsein
fÃ¼r die Problemstellung hat [Sea80].


2.3.1 Sichten


Ausgehend von diesen frÃ¼hen Versuchen den Begriff der KI zu fassen und
zu vermessen, haben sich Ã¼ber die Zeit eine Vielzahl an Definitionen entwi-
ckelt, die teils kontrovers diskutiert werden [Mon20]. In Folge findet sich in
der Literatur auch heute keine einheitliche Definition der KI (engl. Artifici-
al Intelligence (AI)). Vielmehr wird der Begriff aus unterschiedlichen Sichten
heraus nutzbar gemacht.


Eine dieser Sichten betrifft das Vorhandenseins eines Bewusstseins seitens der
Maschine (vgl. Tabelle 2.1). In diesem Sinne lÃ¤sst sich basierend auf Searle
die KI in â€starkâ€œ (engl. strong) bzw. â€schwachâ€œ (engl. weak) einteilen [Sea80].
Man spricht von starker KI, sofern eine Maschine zu Selbsterkenntnis und
Bewusstsein fÃ¤hig ist und autonom handelt â€“ die Maschine weiÃŸ in diesem
Sinne also, was sie tut, warum sie es tut, und ist in der Lage, selbstÃ¤ndig neue
Aufgaben zu finden und diese zu reflektieren. Im Gegenzug spricht man von
schwacher KI, wenn eine Maschine VerstÃ¤ndnis nur â€vortÃ¤uschtâ€œ, tatsÃ¤chlich
jedoch unreflektiert und ohne Bewusstsein eine Aufgabe abarbeitet [Sea80].


Eine weitere Sicht nimmt Bezug auf die Art der Aufgabe, die mittels KI be-
wÃ¤ltigt werden kann, indem zwischen einer sogenannten â€eingeschrÃ¤nktenâ€œ
(engl. narrow) und â€allgemeinenâ€œ (engl. general) KI unterschieden wirdÂ¹. Die
bislang erzielten groÃŸen Erfolge im Forschungsfeld der KI sind dem Bereich
eingeschrÃ¤nkten KI zuzuschreiben: Zwar kÃ¶nnen Maschinen Menschen Ã¼ber-
treffen, jedoch nur in einer eng gefassten Aufgabenstellung (beispielsweise
Go-Spiel, Maschinelles Ãœbersetzen) [Bun17, Kur05]. Im Falle der allgemeinen
KI, ist eine Maschine unabhÃ¤ngig von einem konkreten Anwendungsfall in
der Lage, verschiedenartige Probleme aus unterschiedlichen Bereichen anzu-
gehen [Mon20].


Wie eine Problemstellung innerhalb der KI reprÃ¤sentiert und eingebracht
wird, wurde schon zu Beginn der KI-Forschung intensiv untersucht. Die


FOOTNOTE:Â¹ Hinweis: Das englische Wort â€narrowâ€œ wird in der deutschsprachigen Literatur teils mit
â€schwachâ€œ Ã¼bersetzt. UnabhÃ¤ngig davon wird das englische Wort â€generalâ€œ auch mit â€univer-
sellâ€œ Ã¼bersetzt.


sogenannte â€symbolischeâ€œ (engl. symbolic) KI stellt eine Sichtweise dar, bei
der eine symbolische Ebene [New76, New07], beispielsweise in Form von
durch den Menschen vorgegebener Regeln, genutzt wirdÂ¹. Aus der heuti-
gen Perspektive wird dieser Ansatz teilweise auch als â€Top-Downâ€œ Ansatz
bezeichnet, wÃ¤hrend abgrenzend dazu der â€Bottom-Upâ€œ Ansatz in der An-
wendung subsymbolischer Methoden des Maschinellen Lernens im Sinne der
Problemstellung besteht.


Letzterer wird, gerade bei Verwendung von KÃ¼nstlichen Neuronalen Netzen,
mit dem Begriff der â€konnektionistischenâ€œ (engl. connectionist) oder â€neuro-
nalenâ€œ (engl. neural) KI verknÃ¼pft [Smo87, Smo90].


Tabelle 2.1: Drei Sichten auf den Begriff der KI. Die Sichten beleuchten verschiedene Aspekte,
wie das Vorhandensein eines Bewusstseins, der UniversalitÃ¤t der Intelligenz oder
der ReprÃ¤sentation der Problemstellung.


2.3.2 Verbindungen


Das Forschungsfeld der KI ist mit verschiedenen weiteren Forschungsfeldern
verknÃ¼pft. Im Bereich der Informatik bestehen starke Verbindungen zu den


FOOTNOTE:Â¹ Hinweis: In diesem Zusammenhang wird die symbolische KI auch als Good Old-Fashioned
Artificial Intelligence (GOFAI) bezeichnet [Hau89] und bezieht sich damit auf die symbolische
ReprÃ¤sentation der Wissensbasen frÃ¼herer Expertensysteme.


Abbildung 2.2: Die Abbildung zeigt ein Mengendiagramm zur Verdeutlichung der Zusammen-
hÃ¤nge zwischen den Begriffen KÃ¼nstliche Intelligenz, Maschinelles Lernen, Wis-
senbasierte Systeme und Expertensysteme. Die Punkte A, B und C verdeutlichen
den Schnitt dieser Mengen mit der Menge der KÃ¼nstlichen Intelligenz. Dabei
nutzt KI die Methoden des Maschinellen Lernens (C). Neben dem Aspekt des
Lernens spielt auch die Wissensbasierte Modellierung in Form von Wissensba-
sierten Systemen und insbesondere Expertensystemen eine Rolle. Letztere kÃ¶n-
nenreinauf FormalisierungvonExpertenwissen(A)oderauf einerKombination
mit erlerntem Wissen (B) basieren.


Methoden des Maschinellen Lernens. Hierbei kann KI die Methoden des Ma-
schinellen Lernens auf symbolischer Ebene (bspw. Ã¼ber EntscheidungsbÃ¤ume)
oder subsymbolischer Ebene (bpsw. Neuronale Netze) nutzen (vgl. Abbildung
2.2, Punkt C). Die Teilmenge des Bereichs des Maschinellen Lernens, die sich
speziell mit mehrschichtigen Neuronalen Netzen beschÃ¤ftigt, wird auch Tie-
fes Lernen (engl. Deep Learning [Goo16]) genannt â€“ diese Teilmenge ist aus
GrÃ¼nden der Ãœbersichtlichkeit nicht Bestandteil der Abbildung.


Die Begriffe dieser Mengen werden teils synonym mit dem Begriff der KI ver-
wendet. Sie werden hier aber als mÃ¶gliche Werkzeuge zur Umsetzung von KI
gesehen.


FÃ¼r das LÃ¶sen konkreter Anwendungsprobleme im Rahmen der KI sind neben
dem Aspekt des Lernens jedoch auch weitergehende Aspekte von Interesse.
Beispielsweise die wissensbasierte Modellierung im Kontext der Experten-
systeme, die u.a. die Trennung von Wissensbasis und Wissensverarbeitung
vorsieht (vgl. Kapitel 2.1 und 2.2 ab Seite 7). Dabei kann die Wissensbasis
klassisch durch Formalisierung menschlichen Vorwissens befÃ¼llt werden (A).
Eine Kombination mit Methoden des Maschinellen Lernens, also der Kombi-
nation von menschlichen Vorwissen und Wissen aus Daten, ist dabei ein viel-
sprechender aber auch herausfordernder Ansatz der im Rahmen dieser Arbeit
verfolgt wird (B)Â¹.


2.4 Bayes-Netze als Komponente zur
ProblemlÃ¶sung


Zur EinfÃ¼hrung werden verschiedene Wahrscheinlichkeitsbegriffe in Kapitel
2.4.1 beleuchtet. Daran anschlieÃŸend folgen in Kapitel 2.4.2 die Grundlagen
FOOTNOTE:der Wahrscheinlichkeitstheorie. In den darauf folgenden Kapiteln 2.4.3 und
2.4.4 werden Bayes-Netze genauer besprochen.


2.4.1 Wahrscheinlichkeitsbegriffe


Historisch haben sich unterschiedliche Deutungen des Wahrscheinlichkeits-
begriffs herausgebildet â€“ die frequentistische Sichtweise und die Bayesâ€™sche
Sichtweise â€“ auf die im Folgenden kurz eingegangen wird.


FOOTNOTE:Â¹ Hinweis: Teils wird die Verbindung von KI mit menschlichem (Vor-)wissen auch als Hybride
Intelligenz bezeichnet [Kam16, Del19].


Die frequentistische Sichtweise wurde erstmals im 19. Jahrhundert von John
Venn als mathematische Theorie ausgearbeitet, vgl. [Ven66]. Diese Sichtwei-
se interpretiert die Wahrscheinlichkeit fÃ¼r das Eintreten eines Ereignisses als
die relative HÃ¤ufigkeit, mit der dieses Ereignis in einer unendlichen Anzahl
gleicher und voneinander unabhÃ¤ngiger Zufallsexperimente auftritt. Wahr-
scheinlichkeit wird in der frequentistischen Sicht also auf einen bestimmten
physikalischen Prozess bzw. dessen Ergebnis bezogen.


Damit kann der frequentistische Wahrscheinlichkeitsbegriff dann angewen-
det werden, wenn Ereignisse beliebig oft und unter gleichen UmstÃ¤nden wie-
derholbar sind oder dies zumindest denkbar wÃ¤re. So beispielsweise beim
MÃ¼nzwurf oder beim Erfassen einer MessgrÃ¶ÃŸe. Nicht mÃ¶glich ist jedoch eine
Bewertung von einmaligen Ereignissen (â€Wie hoch ist die Wahrscheinlichkeit,
dass es morgen Nachmittag regnet?â€œ) oder von Hypothesen (â€Es gibt Leben
in anderen Galaxienâ€œ).


Dies gelingt jedoch mittels des Bayesâ€™schen Wahrscheinlichkeitsbegriffes, der
den frequentistischen Wahrscheinlichkeitsbegriff erweitert [Kor10] und es
insbesondere erlaubt, Vorwissen, beispielsweise von Experten, einzubeziehen
[Mor90].


Die Bayesâ€™sche Deutung interpretiert Wahrscheinlichkeit als ein MaÃŸ dafÃ¼r,
wie sehr man â€“ unter BerÃ¼cksichtigung vorhandenen Wissens, Annah-
men und Daten â€“ vom Eintreten eines Ereignisses Ã¼berzeugt ist [LeÃ³19].
Man spricht daher auch von der Interpretation der Wahrscheinlichkeit als
â€Degree-of-Beliefâ€œ (deutsch: Grad-des-DafÃ¼rhaltens), der einen Wert zwi-
schen 0 (unglaubwÃ¼rdig, falsch) und 1 (glaubwÃ¼rdig, wahr) annehmen kann.
Wahrscheinlichkeit ist damit also nicht nur eine Funktion des Ereignisses an
sich, sondern zusÃ¤tzlich abhÃ¤ngig vom Wissensstand [Mor90].


Innerhalb der Bayesâ€™schen Deutung gibt es noch einmal zwei StrÃ¶mungen mit
unterschiedlichen Interpretationen des Grad-des-DafÃ¼rhaltens: Die subjekti-
ve Deutung und die objektive Deutung [Pre09].


Erstere interpretiert den Bayesâ€™schen Wahrscheinlichkeitsbegriff als persÃ¶nli-
che Ãœberzeugung eines Individuums. Der Grad-des-DafÃ¼rhaltens wird also als


eine individuelle, subjektive Meinung aufgefasst, die so gewÃ¤hlt werden soll-
te, dass sie konform zu den Axiomen nach Kolmorogov [Kol33] ist [Mor90].
Beispielsweise sollten sich der Grad-des-DafÃ¼rhaltens, dass ein Ereignis pas-
siert und der Grad-des-DafÃ¼rhaltens, dass dieses nicht passiert, zu 1 addieren.
Beim Erheben von Wahrscheinlichkeiten werden daher spezielle Techniken
angewandt [Win67], sodass sich anschlieÃŸend eine zu den Axiomen nach Kol-
mogorov konforme Wahrscheinlichkeitsverteilung ableiten lÃ¤sst [Leo54].


Die objektive Deutung sieht im Grad-des-DafÃ¼rhaltens im Gegensatz zu
dessen subjektiver Deutung keine individuelle Meinung. Der Grad-des-
DafÃ¼rhaltens steht hier fÃ¼r eine allgemeine, neutrale Erwartung, die jeder
mit dem gleichen Wissensstand teilen sollte. So sollte beispielsweise bei
Nichtvorhandensein relevanter Evidenzen der Grad-des-DafÃ¼rhaltens ge-
mÃ¤ÃŸ des Indifferenz-PrinzipsÂ¹, gleichmÃ¤ÃŸig auf alle in Betracht kommenden
mÃ¶glichen Ereignisse verteilt werden [Eva19].


Auf dem Konzept der Maximalen Entropie basieren zudem weitere Metho-
den zur Konstruktion allgemeiner A-priori-Wahrscheinlichkeitsverteilungen
[Jay88]. Jeffrey schlug spezielle, sogenannte â€nicht-informativeâ€œ Referenz-
Wahrscheinlichkeitsverteilungen vor, die gegenÃ¼ber einer Reparametrisie-
rung der Modellparameter invariant sind [Jef46].


FÃ¼r diese Arbeit von Bedeutung ist die subjektive Interpretation des Grad-des-
DafÃ¼rhaltens, da sie es erlaubt, vorhandenes Expertenwissen durch Exper-
tenbefragungen gezielt in die Wissensbasis einflieÃŸen zu lassen. Eine Heraus-
forderung dabei ist, dass der Grad-des-DafÃ¼rhaltens in diesem Fall abhÃ¤ngig
vom spezifischen Wissensstand und der Informationsverarbeitung der befrag-
ten Person ist. Verschiedene Personen kÃ¶nnen demselben Ereignis somit un-
terschiedliche Wahrscheinlichkeiten zuordnen [Eis13]. Betrifft die EinschÃ¤t-
zung der Experten jedoch empirische GrÃ¶ÃŸen, wie in dieser Arbeit, ist eine
valide Annahme, dass sich die angegebenen Wahrscheinlichkeiten zumindest
Ã¤hneln werden â€“ sofern die Experten einen ausreichend groÃŸen, Ã¤hnlichen


FOOTNOTE:Â¹ Hinweis: Auch als Prinzip des unzureichenden Grundes bezeichnet [Lau98].


Erfahrungsschatz besitzen. Denn nach Morgan und Henrion konvergiert ei-
ne subjektiv gewÃ¤hlte Wahrscheinlichkeitsverteilung einer empirischen GrÃ¶-
ÃŸe gegen deren frequentistische Wahrscheinlichkeitsverteilung, wenn fÃ¼r die
Konstruktion der subjektiven Verteilung mehr und mehr Evidenzen herange-
zogen werden [Mor90].


Der erfahrene Experte kann in der hier vorgebrachten Argumentation als Be-
obachter historischer, nicht in einer Datenbasis vorhandenen Evidenzen an-
gesehen werden, die auf dem Wege der Expertenbefragung dennoch implizit
in die Wissensbasis eingebracht werden kÃ¶nnen. Weiterhin existieren in der
Literatur diverse Verfahren zur Kombination unterschiedlicher Expertenmei-
nungen [Jac95].


2.4.2 Wahrscheinlichkeitstheorie


Ein zentrales Element der Wahrscheinlichkeitstheorie ist ein Ereignis (vgl.
Abschnitt 2.4.1). Dieses kann beispielsweise gegeben sein durch das Ergeb-
nis eines GlÃ¼cksrad-Gewinnspiels, wie in Abbildung 2.3 dargestellt.


Es werde der Raum solcher Ergebnisse mit Î© bezeichnet. FÃ¼r den Ereignis-
raum ğ‘† gelten nun die drei Eigenschaften:


1. âˆ… âˆˆ ğ‘† und Î© âˆˆ ğ‘†,


2. Wenn ğ›¼, ğ›½ âˆˆ ğ‘†, dann ğ›¼ âˆª ğ›½ âˆˆ ğ‘†,


3. Wenn ğ›¼ âˆˆ ğ‘†, dann Î© \ ğ›¼ âˆˆ ğ‘†.


Nun mÃ¼ssen fÃ¼r einen Abbildung von ğ‘† nach â„ und mithin fÃ¼r eine Wahr-
scheinlichkeitsverteilung ğ‘ƒ Ã¼ber (Î©, ğ‘†) noch die drei Axiome nach Kolomo-
gorow [Kol33] erfÃ¼llt sein:


1. ğ‘ƒ(ğ›¼) â‰¥ 0 fÃ¼r alle ğ›¼ âˆˆ ğ‘†,


2. ğ‘ƒ(Î©) = 1,


3. Wenn ğ›¼, ğ›½ âˆˆ ğ‘† und ğ›¼ âˆ© ğ›½ = âˆ…, dann ğ‘ƒ(ğ›¼ âˆª ğ›½) = ğ‘ƒ(ğ›¼) + ğ‘ƒ(ğ›½).


Als anschauliches Beispiel sei das GlÃ¼cksrad-Gewinnspiel in Abbildung 2.3
gegeben. Die FlÃ¤chen des Rades sind mit rÃ¶mischen Ziffern versehen. Der Er-
gebnisraum ist durch Î© = {I, II, III} gegeben. Die Potenzmenge ğ‘† mÃ¶glicher
Ereignisse beinhaltet sowohl Î© = {I, II, III} als auch âˆ… = { }. Das Ereignis
ğ›¼ = {II} âˆˆ ğ‘† reprÃ¤sentiert ein gerades Ergebnis. Es gilt Î© \ ğ›¼ = {I, III} âˆˆ ğ‘†.
Sei ğ›½ = {I, III} âˆˆ ğ‘†, dann ist ebenso ğ›¼ âˆª ğ›½ = {I, II, III} âˆˆ ğ‘†.


Wenn nun die Wahrscheinlichkeit proportional zur FlÃ¤che vergeben und mit
der GesamtflÃ¤che normiert wird, dann gilt fÃ¼r Abbildung ğ‘ƒ(â‹…) zum Beispiel,
dass ğ‘ƒ(ğ›¼) = ğ‘ƒ({II}) = 0,5. Weil weiterhin ğ›¼ âˆ© ğ›½ = âˆ…, gilt ğ‘ƒ(ğ›¼ âˆª ğ›½) =
ğ‘ƒ({I, II, III}) ist gleich der Summe der einzelnen Abbildungen ğ‘ƒ(ğ›¼) + ğ‘ƒ(ğ›½) =
ğ‘ƒ({II}) + ğ‘ƒ({I, III}) = 1.


Definition 2.3. Die bedingte Wahrscheinlichkeit ist die Wahrscheinlichkeit
des Ereignisses ğ›½ unter Kenntnis des Eintretens des Ereignisses ğ›¼:


Wie sich leicht nachrechnen lÃ¤sst, ergibt sich die bedingte Wahrscheinlichkeit
fÃ¼r die konkreten, sich ausschlieÃŸende Ereignisse, ğ›¼ = {II} und ğ›½ = {I, III} zu:


ğ‘ƒ(ğ›½|ğ›¼) = 0. Das bedeutet, dass sich die a-prior bekannte Wahrscheinlichkeit
ğ‘ƒ(ğ›½) = 0,5 unter Kenntnis des Eintretens des Ereignisses ğ›¼ auf ğ‘ƒ(ğ›½|ğ›¼) = 0
reduziert hat.


Sei nun ein weiteres Ereignis ğ›¾ = {III} mit ğ‘ƒ(ğ›¾) = 0,25 gegeben. Die bedingte
Wahrscheinlichkeit ğ‘ƒ(ğ›¾|ğ›½) ergibt sich nach Gleichung (2.1) zu:


Die a-priori Wahrscheinlichkeit ğ‘ƒ(ğ›¾) = 0,25 hat sich also unter Kenntnis des
Ereignisses ğ›½ (d.h. es liegt ein ungerades Ergebnis vor) auf ğ‘ƒ(ğ›¾|ğ›½) = 0,3 er-
hÃ¶ht. Damit ergibt sich die bedingte Wahrscheinlichkeit anschaulich aus dem
VerhÃ¤ltnis der Ergebnisse die sowohl in ğ›½ als auch in ğ›¾ liegen zu den Ergeb-
nissen die in ğ›½ liegen [Kol09].


Um die Kettenregel der bedingten Wahrscheinlichkeiten zu erhalten, kann
Gleichung 2.1 umgestellt werden zu:


ğ‘ƒ(ğ›¼ âˆ© ğ›½) = ğ‘ƒ(ğ›¼)ğ‘ƒ(ğ›½|ğ›¼) .


Allgemein gilt:


Definition 2.4. Die Kettenregel der bedingten Wahrscheinlichkeiten ist de-
finiert als:


ğ‘ƒ(ğ›¼ âˆ© â€¦ âˆ© ğ›¼ ) = ğ‘ƒ(ğ›¼ )ğ‘ƒ(ğ›¼ |ğ›¼ ) â€¦ ğ‘ƒ(ğ›¼ |ğ›¼ âˆ© â€¦ âˆ© ğ›¼ ) . 0 ğ‘˜ 0 1 0 ğ‘˜ 0 ğ‘˜âˆ’1


Aus Gleichung 2.2 folgt unter Ausnutzung von


ğ‘ƒ(ğ›¼ âˆ© ğ›½) = ğ‘ƒ(ğ›½ âˆ© ğ›¼) sowie
ğ‘ƒ(ğ›¼)ğ‘ƒ(ğ›½|ğ›¼) = ğ‘ƒ(ğ›½)ğ‘ƒ(ğ›¼|ğ›½)


und AuflÃ¶sung nach ğ‘ƒ(ğ›¼|ğ›½) die nachfolgende Definition.


Definition 2.5. Der Satz von Bayes ist definiert als


Dieser ergibt sich ebenso Ã¼ber Gleichung 2.1 derart dass,


Sprich: Mit dem Satz von Bayes lÃ¤sst sich aus den a-priori Wahrscheinlich-
keiten ğ‘ƒ(ğ›¼) und ğ‘ƒ(ğ›½) sowie der Likelihood ğ‘ƒ(ğ›½|ğ›¼) die a-posteriori Wahr-
scheinlichkeit ğ‘ƒ(ğ›¼|ğ›½) berechnen. Das ist besonders dann nÃ¼tzlich, wenn sich
in der praktischen Anwendung die a-posteriore Wahrscheinlichkeit ğ‘ƒ(ğ›¼|ğ›½)
nicht oder nur unter enormen Aufwand bestimmen lÃ¤sst.


Weiterhin kann von Interesse sein, wie Ereignisse voneinander abhÃ¤ngen. FÃ¼r
eine vollstÃ¤ndige UnabhÃ¤ngigkeit gilt [Kol09]:


Definition 2.6. In ğ‘ƒ ist ein Ereignis ğ›¼ unabhÃ¤ngig von einem Ereignis ğ›½, also
ğ‘ƒ âŠ§ (ğ›¼ âŸ‚ ğ›½), wenn ğ‘ƒ(ğ›¼|ğ›½) = ğ‘ƒ(ğ›¼) oder wenn ğ‘ƒ(ğ›½) = 0.


Oder aus einer andere Perspektive betrachtet: ğ‘ƒ genÃ¼gt (ğ›¼ âŸ‚ ğ›½) genau dann
wenn ğ‘ƒ(ğ›¼ âˆ© ğ›½) = ğ‘ƒ(ğ›¼)ğ‘ƒ(ğ›½):


ğ‘ƒ(ğ›¼ âˆ© ğ›½) ğ‘ƒ(ğ›¼)ğ‘ƒ(ğ›½) ğ‘ƒ(ğ›¼|ğ›½) = = = ğ‘ƒ(ğ›¼).
ğ‘ƒ(ğ›½) ğ‘ƒ(ğ›½)


FOOTNOTE:Im Beispiel des GlÃ¼cksrad-Gewinnspiels ist ein Ereignis ğ›¼ = {II} unabhÃ¤ngig 2
FOOTNOTE:von einem Ereignis ğ›¼ = {II} aus einer vorangegangen Drehung des Rades. 1
Es kÃ¶nnen aber auch Ereignisse der selben Drehung unabhÃ¤ngig voneinander
sein.


Zur Veranschaulichung werde das GlÃ¼cksrad aus Abbildung 2.3 auf 6 Kreis-
segmente zu einem fairen GlÃ¼cksrad erweitert: Î© = {I, II, III, IV, V, VI} so-
wie ğ‘ƒ({I}) = ğ‘ƒ({II}) = ğ‘ƒ({III}) = ğ‘ƒ({IV}) = ğ‘ƒ({V}) = ğ‘ƒ({VI}). FÃ¼r dem


fairen GlÃ¼cksrad-Gewinnspiel gilt nun, dass die zwei Ereignisse der selben
Drehung ğ›¼ = {I, III, V} und ğ›½ = {I, II} unabhÃ¤ngig voneinander sind, denn
ğ‘ƒ(ğ›¼|ğ›½) = ğ‘ƒ(ğ›¼). Oder anders ausgedrÃ¼ckt: die a-priore Wahrscheinlichkeit
eines ungerades Ergebnisses ğ‘ƒ(ğ›¼) = 0,5 bleibt auch bei Kenntnis des Ereig-
nisses ğ›½ erhalten.


Ereignisse kÃ¶nnen allerdings auch nur bedingt unabhÃ¤ngig sein. HierfÃ¼r muss
gelten [Kol09]:


Definition 2.7. In ğ‘ƒ ist ein Ereignis ğ›¼ bedingt unabhÃ¤ngig von Ereignis ğ›½
gegeben Ereignis ğ›¾, also ğ‘ƒ âŠ§ (ğ›¼ âŸ‚ ğ›½|ğ›¾), wenn ğ‘ƒ(ğ›¼|ğ›½ âˆ©ğ›¾) = ğ‘ƒ(ğ›¼|ğ›¾) oder wenn
ğ‘ƒ(ğ›½ âˆ© ğ›¾) = 0.


Oder alternativ betrachtet: Eine Verteilung ğ‘ƒ genÃ¼gt (ğ›¼ âŸ‚ ğ›½|ğ›¾) genau dann
wenn ğ‘ƒ(ğ›¼ âˆ© ğ›½|ğ›¾) = ğ‘ƒ(ğ›¼|ğ›¾)ğ‘ƒ(ğ›½|ğ›¾).


Gegeben sei wieder das 6-segmentige, faire GlÃ¼cksrad. DarÃ¼ber hinaus sei-
en zunÃ¤chst zwei abhÃ¤ngige Ereignisse gegeben: ğ›¼ = {I} und ğ›½ = {I, III, V}.
Gegeben eine weiteres Ereignis ğ›¾ = {I, III} sind ğ›¼ und ğ›½ allerdings bedingt
unabhÃ¤ngig: ğ‘ƒ(ğ›¼|ğ›½ âˆ© ğ›¾) = ğ‘ƒ({I} | {I, III, V} âˆ© {I, III}) = ğ‘ƒ({I} | {I, III}) = ğ‘ƒ(ğ›¼|ğ›¾).


Wie zuvor beschrieben, kÃ¶nnen Ereignisse anschaulich Ã¼ber Mengen von
Ergebnissen beschrieben werden. In der Praxis werden Ergebnisse hÃ¤ufig
Ã¼ber Werte referenziert und zu Mengen gebÃ¼ndelt. Bei der fairen GlÃ¼cksrat-
Lotterie kÃ¶nnte dies zum Beispiel die Menge alle ungeraden Ergebnisse
sein.


Nach [Kol09] ist die Zuweisung solcher Werte zu einem Ergebnis gegeben
durch:


Definition 2.8. Eine Zufallsvariable ğ‘‹ sei definiert als eine Funktion ğ¹ . ğ‘‹
Diese Funktion weist jedem Ergebnis ğœ” âˆˆ Î© einen Wert ğ‘¥ zu.


Ein Ereignis kann also Ã¼ber {ğœ” âˆˆ Î© âˆ¶ ğ¹ (ğœ”) = ğ‘¥} angegeben werden â€“ oder ğ‘‹
in Kurzschreibweise ğ‘‹ = ğ‘¥. Dabei wird eine Zufallsvariable ğ‘‹ als diskret
bezeichnet, wenn der Wertebereich Val(ğ‘‹) von ğ‘‹ endlich oder abzÃ¤hlbar ist


â€“ sie kann aber auch kontinuierlich sein, beispielsweise reellwertig [Nea04].
Gilt |Val(ğ‘‹)| = 2, wird die Zufallsvariable ğ‘‹ in dieser Ausarbeitung als binÃ¤r
bezeichnet.


Im Beispiel der fairen GlÃ¼cksrad-Lotterie weise eine Zufallsvariable ğ‘‹ jedem
Ergebnis zu, ob dieses ungerade oder gerade ist. Das bedeutet, der Werte-
bereich der binÃ¤ren Zufallsvariablen ist gegeben durch den Wertebereich
Val(ğ‘‹) = {ungerade, gerade}. Ein bestimmtes Ereignis kann zum Beispiel an-
gegeben werden als {ğœ” âˆˆ Î© âˆ¶ ğ¹ (ğœ”) = gerade} = {II, IV, VI}. In Verbindung ğ‘‹
mit ğ‘ƒ(â‹…) ergibt sich die Schreibweise: ğ‘ƒ(ğ‘‹ = gerade) = ğ‘ƒ({II, IV, VI}). Sofern
sich aus dem Kontext die Zufallsvariable bereits ergibt, wird diese auch
weggelassen, also im Beispiel statt ğ‘ƒ(ğ‘‹ = gerade) vereinfachend ğ‘ƒ(gerade)
geschrieben.


2.4.3 Definition


Um im Rahmen einer probabilistischen Wissensbasis eine multivariate Ver-
FOOTNOTE:teilung ğ‘ƒ Ã¼ber Zufallsvariablen ğ‘‹ = ğ‘‹ , â€¦ , ğ‘‹ angeben zu kÃ¶nnen, muss 0âˆ¶ğ‘› 0 ğ‘›
eine Vielzahl an Parametern festgelegt werden. Selbst in einem einfachen Falle
von binÃ¤ren Zufallsvariablen mÃ¼ssten 2ğ‘›+1 mÃ¶gliche Ergebniskombinationen
FOOTNOTE:parametrisiert werden, d.h. 2ğ‘›+1 âˆ’ 1 Parameter gesetzt werden. FÃ¼r 12 binÃ¤re
Zufallsvariablen ergeben sich also 4096 âˆ’ 1 = 4095 Parameter. Offensichtlich
steigt die Anzahl der Parameter exponentiell mit der Anzahl der Zufallsvaria-
blen [Phi15b].


Problematisch ist dies zum Beispiel, wenn diese Parameter im Rahmen ei-
ner Expertenbefragung erhoben werden sollen. Neben dem rein quantitativen
Aspekt, ist die Frage, ob Experten dabei Ã¼berhaupt sinnvolle Wahrscheinlich-
keitswerte fÃ¼r sÃ¤mtliche Ergebniskombination abschÃ¤tzen kÃ¶nnen [Phi16b].
Aber auch wenn Wahrscheinlichkeitswerte aus gegebenen Daten robust ge-
lernt werden sollen, kann dies im Hinblick auf die sehr groÃŸe Anzahl an Para-
metern und der dafÃ¼r notwendigen Datenmenge problematisch sein [Kol09].
Solcherlei GrÃ¼nde waren zunÃ¤chst der Hemmschuh fÃ¼r den Einsatz probabi-
listischer Wissensbasen in frÃ¼heren Wissensbasierten Systemen bzw. Exper-
tensystemen [Kol09].


Mit Hilfe des Formalismus Bayes-Netz (BN) und der Ausnutzung von Unab-
hÃ¤ngigkeit zwischen Zufallsvariablen kÃ¶nnen probabilistische Wissensbasen
allerdings kompakter dargestellt und handhabbar reprÃ¤sentiert werden.


Definition 2.9. Ein BN Ã¼ber den Zufallsvariablen ğ‘‹ = ğ‘‹ , â€¦ , ğ‘‹ ist ge- 0âˆ¶ğ‘› 0 ğ‘›
geben durch ein Tupel


(ğº, ğ‘ƒ) ,


wobei ğº einen gerichteten, azyklischen Graphen


und


die gemeinsame Wahrscheinlichkeitsverteilung reprÃ¤sentieren [Kol09].


Der Graph ğº wird verwendet, um AbhÃ¤ngigkeiten zwischen Zufallsvariablen
FOOTNOTE:ğ‘‹ zu definieren. Er wird auch als Struktur des BN bezeichnet und Ã¤uÃŸerst 0âˆ¶ğ‘›
sich als gerichteter (engl. directed) azyklischer Graph (DAG). Seine Knoten-
bzw. Vertexmenge ğ’± reprÃ¤sentiert die Zufallsvariablen ğ‘‹ . 0âˆ¶ğ‘›


WÃ¤hrend eine gerichtete Kante ğ‘£ â†’ ğ‘£ der Kantenmenge â„° eine direkte Ab- ğ‘– ğ‘—
hÃ¤ngigkeit zwischen zwei Variablen angibt, symbolisiert eine fehlende Kante
die UnabhÃ¤ngigkeit zweier VariablenÂ¹.


FOOTNOTE:Â¹ Hinweis: Da Graph ğº sowohl gerichtet als auch azyklisch ist, existiert kein Pfad der von einem
Knoten zu sich selbst zurÃ¼ck fÃ¼hrt: âˆ„ Pfad ğ‘£ğ‘– â†’ â€¦ â†’ ğ‘£ğ‘–.


Die gemeinsame Wahrscheinlichkeitsverteilung ist durch das Produkt aller
bedingten Wahrscheinlichkeitsverteilungen gegeben, welche mit den Kno-
ten von ğº verknÃ¼pft sind. Sie reprÃ¤sentiert die Parameter des BN. Dabei be-
zeichnet Pa(ğ‘‹ ) die Menge der ElternÂ¹ einer Zufallsvariablen ğ‘‹ . Im Graphen ğ‘– ğ‘–
entspricht dies Knoten mit einer gerichteten Kante zum Knoten der mit ğ‘‹ ğ‘–
verknÃ¼pft istÂ². Die Faktoren ğ‘ƒ(ğ‘‹ |Pa(ğ‘‹ )) werden als Conditional Probability ğ‘– ğ‘–
Distribution â€“ bedingte Wahrscheinlichkeitsverteilung (CPD) bezeichnet. Im
Falle diskreter Zufallsvariablen kÃ¶nnen sogenannte Conditional Probability
Tables â€“ bedingte Wahrscheinlichkeitstabellen (CPT) herangezogen werden,
um die Verteilungen zu reprÃ¤sentieren.


Bei der obigen Darstellung wird angenommen, dass ğº eine I-MAP (engl. Inde-
pence Map) der Wahrscheinlichkeitsverteilung ğ‘ƒ ist, d.h. dass jede UnabhÃ¤n-
gigkeitsbeziehung, die durch ğº gegeben ist, auch in ğ‘ƒ erfÃ¼llt istÂ³ [Kol09]. Nur
in diesem Falle kann die Berechnung von ğ‘ƒ durch die bedingten UnabhÃ¤n-
gigkeiten so vereinfacht werden, dass sich die â€Kettenregel der Bayesschen
Netzeâ€œ, wie in Formel (2.5) dargestellt, ergibt.


Um die fÃ¼r die I-MAP benÃ¶tigten bedingten UnabhÃ¤ngigkeiten formal ange-
ben zu kÃ¶nnen, mÃ¼ssen folgende Knotenmengen definiert werden:


â€¢ Pa(ğ‘‹ ): Menge der Knoten, von denen eine gerichtete Kante nach ğ‘‹ ğ‘– ğ‘–
fÃ¼hrt (d.h. die Eltern von ğ‘‹ ), ğ‘–


â€¢ Desc(ğ‘‹ ): Menge der Knoten, die auf einem von ğ‘‹ ausgehenden Pfad ğ‘– ğ‘–
liegen (d.h. die Nachfahren von ğ‘‹ ), ğ‘–


â€¢ NDesc(ğ‘‹ ): Menge der Knoten, die weder in Pa(ğ‘‹ ) noch in Desc(ğ‘‹ ) ğ‘– ğ‘– ğ‘–
liegen, sowie nicht ğ‘‹ selbst sind (d.h. Nicht-Nachfahren von ğ‘‹ ). ğ‘– ğ‘–


Â¹ Hinweis: Durch den verwendeten DAG (mit seiner azyklischen sowie gerichteten Eigenschaft)
ist sichergestellt, dass die Elternbeziehung eindeutig fÃ¼r jeden Knoten angegeben werden kann.


ist sichergestellt, dass die Elternbeziehung eindeutig fÃ¼r jeden Knoten angegeben werden kann.
FOOTNOTE:Â² Hinweis: Wenn Pa(ğ‘‹ ) = âˆ…, ist die Zufallsvariable ğ‘‹ ein Wurzelknoten und ğ‘ƒ(ğ‘‹ | âˆ…) = ğ‘– ğ‘– ğ‘–
ğ‘ƒ(ğ‘‹ ) gibt folglich die A-priori-Wahrscheinlichkeit an. ğ‘–


FOOTNOTE:Â³ Hinwğ‘–eigs:ibUtmfoglgekliechhrdtime AÃ¼s-spernioraib-WeranhircshcthaelilneliUchnkaebihtÃ¤anng.igkeiten in ğ‘ƒ auch in ğº reprÃ¤sentiert
sein.


Abbildung 2.4: Bayessches Netz aus [Kol09, Kor10, Dar09] in Anlehnung an [Pea88]. Graph mit
Knoten und zugeordneten bedingten Wahrscheinlichkeitsverteilungen. Es gilt:
ğ‘ƒ(ğ´,ğ¸,ğ¾,ğ‘,ğ‘†) = ğ‘ƒ(ğ´)ğ‘ƒ(ğ¸|ğ‘)ğ‘ƒ(ğ‘|ğ´,ğ¾)ğ‘ƒ(ğ¾)ğ‘ƒ(ğ‘†|ğ´).


Mit diesen Knotenmengen kann die lokale Markovbedingung, die der I-MAP
zugrunde liegt, definiert werden:


Definition 2.10. Der DAG ğº eines Bayes-Netzes, dessen Knoten ğ‘£ die Zu-
fallsvariablen ğ‘‹ reprÃ¤sentieren, steht fÃ¼r die Menge der lokalen bedingten 0âˆ¶ğ‘›
UnabhÃ¤ngigkeiten


Die lokale Markovbedingung besagt also, dass jeder Knoten (ğ‘‹ ) bedingt ğ‘–
unabhÃ¤ngig von nicht-nachfolgenden Knoten ist, gegeben seine Eltern, vgl.
[Kol09].


Beispielhaft sei das Bayes-Netz in Abbildung 2.4 gegeben. Sein DAG stellt
Knoten und die jeweils verknÃ¼pften Zufallsvariablen aus der Menge


{ğ´, ğ¸, ğ¾, ğ‘, ğ‘†} dar. Aus didaktischen GrÃ¼nden tragen die Knoten zusÃ¤tz-
lich eine sprechende Bezeichnung. Deutet man die Kanten in einem kausalen
Zusammenhang (Ursache und Wirkung), so kÃ¶nnen sowohl das Kursniveau
als auch die Auffassungsgabe eines Studenten seine Note beeinflussen. Die
Note wiederum beeinflusst die QualitÃ¤t des Empfehlungsschreibens. Die Auf-
fassungsgabe beeinflusst zudem das Ergebnis des StudienfÃ¤higkeitstest (engl.
Scholastic Assessment Test, SAT)Â¹. Auch fehlende Kanten sind bedeutungs-
tragend: Die nicht vorhandene Kante zwischen dem Knoten Kursniveau und
dem Knoten Auffassungsgabe zeigt an, dass die verknÃ¼pften Zufallsvariablen
ğ¾ und ğ´ unabhÃ¤ngig voneinander sind.


Durch den DAG in Abbildung 2.4 ist die Menge der lokalen bedingten Unab-
hÃ¤ngigkeiten wie folgt festgelegt:


ğ¼ (ğº) = {(ğ¸ âŸ‚ ğ´,ğ¾,ğ‘†|ğ‘), (ğ‘† âŸ‚ ğ¸, ğ¾, ğ‘€|ğ´), (ğ‘ âŸ‚ ğ‘†|ğ´, ğ¾), ğ‘™
(ğ¾ âŸ‚ ğ´, ğ‘†|âˆ…), (ğ´ âŸ‚ ğ¾|âˆ…)} .


2.4.4 d-Separation


In Definition 2.10 aus Kapitel 2.4.3 wurde gezeigt, dass durch den Graphen
ğº = (ğ‘‰,ğ¸) eines Bayes-Netzes die Menge lokaler bedingter UnabhÃ¤ngigkei-
ten ğ¼ (ğº) gegeben ist. ğ‘™


DarÃ¼ber hinaus kann ein Graph weitere, sogenannte globale MarkovunabhÃ¤n-
gigkeiten enthalten. Diese lassen sich mittels des Konzeptes der d-Separation
prÃ¼fen [Gei90]. Dieses Konzept kann genutzt werden, um zu Ã¼berprÃ¼fen ob
zwei Mengen an Zufallsvariablen gegeben einer Menge anderer Zufallsvaria-
blen unabhÃ¤ngig von einander sind.


Um dieses Konzept herzuleiten wird zunÃ¤chst der Begriff des (aktiven) Weges
definiert, vgl. [Gei90] und [Kol09]:


FOOTNOTE:Â¹ Hinweis: Eine detaillierte Darstellung dieses Beispiels findet sich auch in der einschlÃ¤gigen
Literatur [Kol09, Kor10, Pea88].


Definition 2.11. Gegeben sei der Graph ğº = (ğ’±, â„°) eines Bayes-Netzes mit
FOOTNOTE:Zufallsvariablen ğ‘‹ . Weiterhin sei ğ’µ eine Teilmenge der Zufallsvariablen, 0âˆ¶ğ‘›
die beobachtet wurde. ğ’µ sei durch die Knotenmenge ğ’± âŠ† ğ’± reprÃ¤sentiert. Ein ğ’µ
Weg ist eine Sequenz von Kanten, die in der ungerichteten ReprÃ¤sentation des
DAGs ğº = (ğ’±, â„°) einen Pfad (Sequenz von Knoten) bildetÂ¹. HierfÃ¼r schreibt
man auch ğ‘£ â‡Œ â‹¯ â‡Œ ğ‘£ mit ğ‘£ , â€¦ , ğ‘£ âˆˆ ğ’±. 0 ğ‘š 0 ğ‘š


Ein solcher Weg wird als aktiver Weg gegeben ğ’µ bezeichnet, falls:


FOOTNOTE:1. FÃ¼r jede existierende konvergierende Verbindung ğ‘£ â†’ ğ‘£ â† ğ‘£ ğ‘–âˆ’1 ğ‘– ğ‘–+1
innerhalb des Weges, liegen entweder ğ‘£ oder einer seiner Nachfolger ğ‘–
in ğ’± . ğ’µ


2. Kein anderer Knoten des Weges liegt in ğ’± . ğ’µ


Insbesondere ist der Weg ğ‘£ â‡Œ â‹¯ â‡Œ ğ‘£ nicht aktiv, wenn ğ‘£ oder ğ‘£ in ğ’± 0 ğ‘š 0 ğ‘š ğ’µ
liegen.


Mithilfe der Definition eines aktiven Weges kann das Konzept der d-
Separation definiert werden[Gei90]:


Definition 2.12. Seien ğ’², ğ’´ und ğ’µ drei disjunkte Teilmengen der Zufalls-
variablen, die in der Struktur ğº = (ğ’±, â„°) eines Bayes-Netzes durch die dis-
junkten Knotenmengen ğ’±ğ’², ğ’±ğ’´ und ğ’±ğ’µ reprÃ¤sentiert werden. Dann heiÃŸt ğ’²
d-separiert von ğ’´ gegeben ğ’µ genau dann, wenn es keinen aktiven Weg zwi-
schen beliebigen Knoten ğ‘£ğ’² âˆˆ ğ’±ğ’² und ğ‘£ğ’´ âˆˆ ğ’±ğ’´ gibt, gegeben ğ’±ğ’µ.


Mit dem Konzept der d-Separation kÃ¶nnen die globalen MarkovunabhÃ¤ngig-
keiten beschrieben werden.


FOOTNOTE:Â¹ Hinweis: Die Begriffe Weg und Pfad werden in der deutschsprachigen Literatur teils synonym
verwendet. Hier sind die Ãœbersetzungen der Begriffe trail (= Sequenz von Kanten) und path (=
Sequenz von Knoten) gemeint, die sich unterscheiden.


Definition 2.13. Sei ğº der DAG eines Bayes-Netzes und ğ’², ğ’´ und ğ’µ dis-
junkte Teilmengen der durch die Knoten des DAG reprÃ¤sentierten Zufallsva-
riablen. Dann sind die globalen MarkovunabhÃ¤ngigkeiten von ğº definiert als:


ğ¼(ğº) = {(ğ’² âŸ‚ ğ’´|ğ’µ) âˆ¶ ğ’² ist d-separiert von ğ’´ gegeben ğ’µ .} (2.7)


FÃ¼r das Beispiel in Abbildung 2.4 sind somit die globalen MarkovunabhÃ¤ngig-
keiten gegeben durch:


ğ¼(ğº) = {(ğ¸ âŸ‚ ğ´, ğ¾, ğ‘†|ğ‘)} .


2.4.5 Dynamische Aspekte


Ein BN ist ein probabilistisches graphisches Modell (PGM), das graphentheo-
retische AnsÃ¤tze mit AnsÃ¤tzen der Wahrscheinlichkeitstheorie verbindet. Wie
in Kapitel 2.4.3 ausfÃ¼hrlich erlÃ¤utert, ist ein BN Ã¼ber den Zufallsvariablen
ğ‘‹ = ğ‘‹ , â€¦ , ğ‘‹ gegeben durch ein Paar 0âˆ¶ğ‘› 0 ğ‘›


ğµ = (ğº, ğ‘ƒ) .


Dabei ist ğº ein gerichteter, azyklischer Graph


und


die gemeinsame Wahrscheinlichkeitsverteilung [Kol09].


Der Graph ğº wird genutzt, um AbhÃ¤ngigkeiten zwischen den Zufallsvariablen
zu definieren und reprÃ¤sentiert damit die Struktur des BN (vgl. Kapitel 2.4.3).
Die Vertexmenge ğ’± reprÃ¤sentiert die Menge der Zufallsvariablen, wÃ¤hrend


FOOTNOTE:Abbildung 2.5: Graph eines Bayes-Netzes (BN) Ã¼ber den Zufallsvariablen ğ‘‹ . Diese Struk- 0âˆ¶4
tur, die auch Naive BN genannt wird, ist gekennzeichnet durch gerichte-
FOOTNOTE:te Kanten ausgehend von Wurzelknoten ğ‘‹ zu seinen Kindern ğ‘‹ . Da 0 1âˆ¶4
eine fehlende Kante die UnabhÃ¤ngigkeit zweier Zufallsvariablen verkÃ¶rpert,
FOOTNOTE:kann die Verbundwahrscheinlichkeit ğ‘ƒ(ğ‘‹ ) wie folgt faktorisiert werden: 0âˆ¶4
ğ‘ƒ(ğ‘‹ ) = ğ‘ƒ(ğ‘‹ )ğ‘ƒ(ğ‘‹ |ğ‘‹ )ğ‘ƒ(ğ‘‹ |ğ‘‹ )ğ‘ƒ(ğ‘‹ |ğ‘‹ )ğ‘ƒ(ğ‘‹ |ğ‘‹ ). 0âˆ¶4 0 1 0 2 0 3 0 4 0


eine gerichtete Kante ğ‘£ â†’ ğ‘£ der Menge der Kanten â„° eine direkte AbhÃ¤n- ğ‘– ğ‘—
gigkeit zwischen zwei Variablen darstellt. Eine fehlende Kante symbolisiert
die UnabhÃ¤ngigkeit dieser beiden Variablen (cf. Figure 2.5).


Die gemeinsame Wahrscheinlichkeitsverteilung reprÃ¤sentiert die Parameter
des BN (vgl. Kapitel 2.4.3) und ist durch das Produkt aller bedingten Wahr-
scheinlichkeitsverteilungen gegeben, die mit den Vertices von ğº verknÃ¼pft
sind. Dabei bezeichnet Pa(ğ‘‹ ) die Menge der Eltern einer Zufallsvariablen ğ‘‹ . ğ‘– ğ‘–


Ein Dynamisches Bayes-Netz (DBN) ist eine Erweiterung eines BN, das auch
die zeitlichen AbhÃ¤ngigkeiten der Zufallsvariablen berÃ¼cksichtigen kann
[Mur02]. Ein DBN ist dabei gegeben durch das Tupel


ğ·ğµğ‘ = (ğµ , ğµ ) . 0 â†’


Ersteres, also ğµ , wird genutzt, um die Struktur als auch die a-priore Wahr- 0
scheinlichkeitsverteilung Ã¼ber den Zufallsvariablen ğ‘‹ in Zeitschritt 0, 0âˆ¶ğ‘›
FOOTNOTE:sprich: ğ‘ƒ(ğ‘‹0 ), anzugeben. Die Struktur von ğµ kann beispielsweise nach 0âˆ¶ğ‘› 0
Abbildung 2.5 erfolgen â€“ die Variablen tragen dann zusÃ¤tzlich einen hochge-
stellten Index des Zeitschritts 0.


Abbildung 2.6: Vereinfachte Darstellung eines zeitlichen Bayes-Netzes mit zwei Zeitscheiben.
Dieses wird im englischsprachigen Raum auch als Temporal Bayesian Network
(TBN) mit zwei Zeitscheiben oder kurz als 2TBN bezeichnet. Das 2TBN (oder
auch: ğµâ†’) wird als Schablone fÃ¼r nachfolgende Zeitschritte ğ‘¡ eingesetzt. Aus
GrÃ¼nden der Ãœbersichtlichkeit sind Knoten der Zufallsvariablen ğ‘‹ğ‘¡âˆ’1 nicht ab- 1âˆ¶4
gebildet, denn es existiert in diesem Beispiel keine direkte AbhÃ¤ngigkeit zu
ğ‘‹0âˆ¶4. Eine solch vereinfachte Darstellung eines 2TBN, also eine Darstellung ğ‘¡
mit nur relevanten Knoten des vorgelagerten Zeitschritts, wird teils als 1,5TBN
bezeichnet [Mur02].


Weiterhin spezifiziert ğµ die bedingte Wahrscheinlichkeitsverteilung Ã¼ber â†’
diskrete Zeitschritte ğ‘¡ hinweg, nÃ¤mlich durch die Verwendung von:


Dabei bezeichnet Pa(ğ‘‹ğ‘¡) die Menge der Eltern von ğ‘‹ğ‘¡ im zugehÃ¶rigen Gra- ğ‘– ğ‘–
phen. Eltern kÃ¶nnen hierin dem selben Zeitschritt ğ‘¡ oder aber dem voran-
gegangenen Zeitschritt ğ‘¡ âˆ’ 1 zugeordnet sein. Im letzteren Falle zeigen ge-
richteten Kanten in Zeitschritte mit hÃ¶herem Index, was das zeitliche Voran-
schreiten widerspiegelt [Mur02]. Abbildung 2.6 zeigt hierzu beispielhaft den
Graphen ğµ eines DBNs. Dabei besitzt der Knoten der Zufallsvariablen ğ‘‹ğ‘¡ â†’ 0
einen Elternknoten im vorgelagerten Zeitschritt ğ‘¡ âˆ’ 1; es existiert also eine
gerichtete Kante Ã¼ber zwei verschiedene Zeitschritte hinweg. Weiterhin exis-
tieren Kanten innerhalb eines Zeitschrittes, beispielsweise zwischen Knoten
der Zufallsvariablen ğ‘‹ğ‘¡ und ğ‘‹ğ‘¡. 0 1


2.5 FHIR zur WissensreprÃ¤sentation


Ziel der FHIRÂ¹ ist die UnterstÃ¼tzung des Austauschs von Informationen zwi-
schen SoftwaresystemenÂ² im medizinischen BereichÂ³. Herausgeber ist die He-
alth Level Seven (HL7)â´ International, welche im Jahr 1987 als non-Profit Or-
ganisation gegrÃ¼ndet wurde und durch das American National Standards In-
stitute (ANSI) seit 27 Jahren als Normungsorgan akkreditiert ist. Gemeinsam
mit der ISO und anderen Normungsorganen werden kontinuierlich interna-
tional einschlÃ¤gige Normen etabliert.


Mit FHIR kÃ¶nnen sowohl Ressourcen als auch Datenformate und Schnittstel-
len spezifiziert werden [Ben21]. Ressourcen sind allerdings die zentralen Bau-
steine der FHIR [Oem21]. Aus diesen allgemeinen Schablonen kÃ¶nnen do-
mÃ¤nentypische Objekte wie beispielsweise Patient (engl. Patient), Untersu-
chungswert (engl. Observation) oder Behandlungsort (engl. Location) abge-
leitet werden. Es stehen 145 verschiedene Ressourcen zur VerfÃ¼gung [FHI21],
die sich gemÃ¤ÃŸ ihres Typus in einer Taxonomie verorten lassen [Ben21]. Mit
BerÃ¼cksichtigung der entsprechenden fachlichen Sicht ergibt sich Tabelle 2.2
auf Seite 36 mit den jeweils beispielhaft dargestellten Ressourcen.


Weitere Ressourcen kÃ¶nnen nach Bedarf hinzugefÃ¼gt werden [Ben21]. Insge-
samt kÃ¶nnen so Daten mittels FHIR auffindbar (engl. Findable), zugÃ¤nglich


Â¹ Gesprochen: [ËˆfaÉªÉ™] (engl. fire).


FOOTNOTE:Â² Hinweis: Systeme werden in der Begriffswelt der Softwaretechnik als Ausschnitte der realen
oder gedanklichen Welt gesehen, welche aus Komponenten, darauf vorhandenen Strukturen
sowie einer Systemgrenze bestehen [Hes84, Bal10]. Letztere wird auch als Schnittstelle oder
seltener als Nahtstelle bezeichnet (engl. interface).


FOOTNOTE:Â³ Hinweis: Der Anwendungsbereich umfasst Human- und VeterinÃ¤rmedizin und hierin die me-
dizinische Versorgung selbst als auch Finanz- und Verwaltungsaspekte[Ben21, FHI21].


â´ Hinweis: Die Zahl 7 ist eine Anspielung auf das Open Systems Interconnection (OSI) Schichten-
modell der International Organization for Standardization (ISO) â€“ hÃ¤ufig kurz als ISO/OSI Mo-
dell bezeichnet [Pro93]. Dieses bezieht sich auf die Verbindung (Interconnection) verschiedener
Systeme. Hierin ist die Schicht 7 die sog. Anwendungsschicht, welche sich mit dem Austausch
von Daten auf Anwendungsebene beschÃ¤ftigt.


